{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import argparse\n",
                "from torch.utils.data import DataLoader\n",
                "from utils.util import set_seed, set_gpu_devices, save_file\n",
                "from networks.model import VideoQAmodel\n",
                "from DataLoader import VideoQADataset\n",
                "import torch.nn as nn\n",
                "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
                "from utils.logger import logger\n",
                "\n",
                "# Import training functions from train.py to ensure consistency\n",
                "from train import train, eval, predict\n",
                "\n",
                "print(\"Libraries imported successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Configuration and Path Setup\n",
                "\n",
                "Here we define the paths for:  \n",
                "1. **Video Features**: `.pt` files organized in `train`, `val`, `test` folders.  \n",
                "2. **Object Features**: Folder containing separate folders for each video ID (e.g. `object_feature_path/video_id/*.pkl`).  \n",
                "3. **Split Directory**: Directory containing `train.txt`, `valid.txt`, and `test.txt` which define the video splits.  \n",
                "4. **Annotation Path**: Path to the standard CSV annotations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    # Data Paths\n",
                "    # Configure these paths according to your actual workspace\n",
                "    video_feature_root = r\"D:\\KLTN\\TranSTR\\causalvid\\features\\vit\"  # Root folder containing train/val/test folders of .pt files\n",
                "    object_feature_path = r\"D:\\KLTN\\TranSTR\\causalvid\\features\\objects\" # Root folder containing video_id subfolders\n",
                "    sample_list_path = r\"D:\\KLTN\\TranSTR\\causalvid\\data\\vqa\\causal\\anno\" # Path to {split}.csv files\n",
                "    split_dir_txt = r\"D:\\KLTN\\TranSTR\\causalvid\\data\\splits\" # Directory containing train.txt, valid.txt, test.txt\n",
                "    \n",
                "    # Model Params\n",
                "    v = \"v1\"\n",
                "    bs = 8 # Batch Size\n",
                "    lr = 1e-4\n",
                "    epoch = 20\n",
                "    gpu = 0\n",
                "    dropout = 0.3\n",
                "    encoder_dropout = 0.3\n",
                "    patience = 5\n",
                "    gamma = 0.1\n",
                "    decay = 1e-4\n",
                "    \n",
                "    # Dataset Params\n",
                "    dataset = 'causal-vid'\n",
                "    objs = 10 # Number of objects\n",
                "    n_query = 5\n",
                "    \n",
                "    # Transformer\n",
                "    d_model = 512\n",
                "    word_dim = 768\n",
                "    topK_frame = 20\n",
                "    topK_obj = 10\n",
                "    num_encoder_layers = 2\n",
                "    num_decoder_layers = 2\n",
                "    nheads = 8\n",
                "    normalize_before = True\n",
                "    activation = 'gelu'\n",
                "    \n",
                "    # Text Encoder\n",
                "    text_encoder_lr = 1e-5\n",
                "    freeze_text_encoder = False\n",
                "    text_encoder_type = \"bert-base-uncased\"\n",
                "    text_pool_mode = 1\n",
                "    \n",
                "    # Misc\n",
                "    hard_eval = False\n",
                "    pos_ratio = 1.0\n",
                "    neg_ratio = 1.0\n",
                "    a = 1.0\n",
                "    use_amp = True\n",
                "    num_workers = 4\n",
                "    frame_feat_dim = 768 # Match your ViT feature dim\n",
                "    obj_feat_dim = 2048 + 5 # Match your object feature dim\n",
                "\n",
                "args = Config()\n",
                "set_gpu_devices(args.gpu)\n",
                "set_seed(999)\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize DataLoaders\n",
                "We use the modified `VideoQADataset` which will now:\n",
                "- Load standard annotations from CSV.\n",
                "- **Filter by Split TXT**: Only include video IDs found in `split_dir_txt/{split}.txt`.\n",
                "- **Filter by Feature Existence**: Only include videos where the `.pt` file actually exists.\n",
                "- **Load Object Features**: From separate folders (e.g. `.../video_id/imageXX.pkl`).\n",
                "\n",
                "This robustly handles cases where you have a list of videos but are missing features for some."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Initializing Datasets...\")\n",
                "\n",
                "try:\n",
                "    # TRAIN\n",
                "    train_dataset = VideoQADataset(\n",
                "        split='train', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt # Passing the split folder\n",
                "    )\n",
                "\n",
                "    # VAL\n",
                "    val_dataset = VideoQADataset(\n",
                "        split='val', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt\n",
                "    )\n",
                "\n",
                "    # TEST\n",
                "    test_dataset = VideoQADataset(\n",
                "        split='test', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt\n",
                "    )\n",
                "\n",
                "    train_loader = DataLoader(dataset=train_dataset, batch_size=args.bs, shuffle=True, \n",
                "                              num_workers=args.num_workers, pin_memory=True)\n",
                "    val_loader = DataLoader(dataset=val_dataset, batch_size=args.bs, shuffle=False, \n",
                "                            num_workers=args.num_workers, pin_memory=True)\n",
                "    test_loader = DataLoader(dataset=test_dataset, batch_size=args.bs, shuffle=False, \n",
                "                             num_workers=args.num_workers, pin_memory=True)\n",
                "\n",
                "    print(\"\\nDatasets initialized successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"\\nError initializing datasets: {e}\")\n",
                "    # Check your paths in Config if this fails."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Verify Data Loading\n",
                "We verify that a batch can be loaded correctly, ensuring dimensions are as expected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    if len(train_loader) > 0:\n",
                "        for sample in train_loader:\n",
                "            vid_frame_feat, vid_obj_feat, qns_word, ans_word, ans_id, qns_key = sample\n",
                "            print(\"--- Data Verification ---\")\n",
                "            print(f\"Frame Features Shape: {vid_frame_feat.shape}\")\n",
                "            print(f\"Object Features Shape: {vid_obj_feat.shape}\")\n",
                "            print(f\"Question Batch Size: {len(qns_word)}\")\n",
                "            print(f\"Sample Question: {qns_word[0]}\")\n",
                "            print(\"--- Verification Passed ---\")\n",
                "            break\n",
                "    else:\n",
                "        print(\"Warning: Train loader is empty. Check your data paths and splits.\")\n",
                "except Exception as e:\n",
                "    print(f\"Data Verification Failed: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Setup and Training\n",
                "We initialize the model with the configuration and start the training loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_dict = {k: v for k, v in Config.__dict__.items() if not k.startswith('__')}\n",
                "config_dict['device'] = device\n",
                "# Ensure compatibility with Model constructor\n",
                "model = VideoQAmodel(**config_dict)\n",
                "\n",
                "# Optimizer config\n",
                "param_dicts = [\n",
                "    {\"params\": [p for n, p in model.named_parameters() if \"text_encoder\" not in n and p.requires_grad]},\n",
                "    {\"params\": [p for n, p in model.named_parameters() if \"text_encoder\" in n and p.requires_grad], \"lr\": args.text_encoder_lr}\n",
                "]\n",
                "optimizer = torch.optim.AdamW(params=param_dicts, lr=args.lr, weight_decay=args.decay)\n",
                "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=args.gamma, patience=args.patience, verbose=True)\n",
                "model.to(device)\n",
                "xe = nn.CrossEntropyLoss().to(device)\n",
                "scaler = torch.cuda.amp.GradScaler(enabled=args.use_amp)\n",
                "\n",
                "print(\"Model and Optimizer created.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Starting Training Loop...\")\n",
                "best_eval_score = 0.0\n",
                "best_epoch = 1\n",
                "\n",
                "# Initialize logger dummy/wrapper if needed or use imported\n",
                "# logger.debug = print # Simple redirect if logger not configured\n",
                "\n",
                "if len(train_loader) > 0:\n",
                "    for epoch in range(1, args.epoch + 1):\n",
                "        print(f\"Epoch {epoch}/{args.epoch}\")\n",
                "        train_loss, train_acc = train(model, optimizer, train_loader, xe, device, use_amp=args.use_amp)\n",
                "        eval_score = eval(model, val_loader, device)\n",
                "        scheduler.step(eval_score)\n",
                "        \n",
                "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f} | Val Acc: {eval_score:.2f}\")\n",
                "        \n",
                "        if eval_score > best_eval_score:\n",
                "            best_eval_score = eval_score\n",
                "            best_epoch = epoch\n",
                "            save_path = f'./models/best_model_epoch_{epoch}.ckpt'\n",
                "            if not os.path.exists('./models'): os.makedirs('./models')\n",
                "            torch.save(model.state_dict(), save_path)\n",
                "            print(f\"  Saved new best model to {save_path}\")\n",
                "        \n",
                "        # Optional: Run test every epoch\n",
                "        test_score = eval(model, test_loader, device)\n",
                "        print(f\"  Test Acc: {test_score:.2f}\")\n",
                "\n",
                "    print(\"Training Complete.\")\n",
                "    print(f\"Best Val Acc: {best_eval_score:.2f} at Epoch {best_epoch}\")\n",
                "else:\n",
                "    print(\"Cannot start training because train_loader is empty.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Test Evaluation\n",
                "Load the best model and evaluate on the test set, saving predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists(f'./models/best_model_epoch_{best_epoch}.ckpt'):\n",
                "    model.load_state_dict(torch.load(f'./models/best_model_epoch_{best_epoch}.ckpt'))\n",
                "    print(\"Loaded best model.\")\n",
                "    \n",
                "results, test_acc = predict(model, test_loader, device)\n",
                "print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
                "\n",
                "# Save results\n",
                "if not os.path.exists('./prediction'): os.makedirs('./prediction')\n",
                "result_path = f'./prediction/results_best_{best_epoch}.json'\n",
                "save_file(results, result_path)\n",
                "print(f\"Predictions saved to {result_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}