{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TranSTR CausalVid - Paper Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Clone\n",
    "import os\n",
    "print('=== CELL 1 ===')\n",
    "if not os.path.exists('tranSTR_Casual'):\n",
    "    !git clone https://github.com/DanielQH07/tranSTR_Casual.git\n",
    "os.chdir('tranSTR_Casual/causalvid' if os.path.exists('tranSTR_Casual/causalvid') else 'tranSTR_Casual')\n",
    "print(f'CWD: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: HuggingFace\n",
    "print('=== CELL 2 ===')\n",
    "!pip install -q huggingface_hub\n",
    "from huggingface_hub import login, HfApi, hf_hub_download, list_repo_tree\n",
    "# notebook_login()\n",
    "login(token='YOUR_HF_TOKEN') # Replace with your actual token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: Imports\n",
    "print('=== CELL 3: Imports ===')\n",
    "import os, torch, numpy as np, pandas as pd, tarfile, shutil, json\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.util import set_seed, set_gpu_devices\n",
    "from DataLoader import VideoQADataset\n",
    "from networks.model import VideoQAmodel\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Train/Eval functions\n",
    "print('=== CELL 4 ===')\n",
    "\n",
    "def train_epoch(model, optimizer, loader, xe, device, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for batch in loader:\n",
    "        ff, of, q, a, ans_id, _ = batch\n",
    "        ff, of, tgt = ff.to(device), of.to(device), ans_id.to(device)\n",
    "        with torch.amp.autocast('cuda', enabled=True):\n",
    "            out = model(ff, of, q, a)\n",
    "            loss = xe(out, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        correct += (out.argmax(-1) == tgt).sum().item()\n",
    "        total += tgt.size(0)\n",
    "    return total_loss / len(loader), correct / total * 100\n",
    "\n",
    "def eval_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            ff, of, q, a, ans_id, _ = batch\n",
    "            out = model(ff.to(device), of.to(device), q, a)\n",
    "            correct += (out.argmax(-1) == ans_id.to(device)).sum().item()\n",
    "            total += ans_id.size(0)\n",
    "    return correct / total * 100\n",
    "\n",
    "print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Organize Kaggle Object Features Dataset\n",
    "# This cell reads pre-extracted object features from Kaggle input and organizes them\n",
    "# into the directory structure expected by DataLoader.py\n",
    "print('=== CELL 5: Organize Object Features ===')\n",
    "import pickle as pkl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS\n",
    "# ============================================\n",
    "KAGGLE_INPUT_PATH = '/kaggle/input/YOUR_DATASET_NAME'  # Change this!\n",
    "BASE = '/kaggle/working' if os.path.exists('/kaggle/working') else os.getcwd()\n",
    "OBJ_DIR = os.path.join(BASE, 'features', 'objects')\n",
    "MODEL_DIR = os.path.join(BASE, 'models')\n",
    "\n",
    "os.makedirs(OBJ_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# CHECK IF ALREADY ORGANIZED\n",
    "# ============================================\n",
    "def count_organized_videos():\n",
    "    \"\"\"Count videos that have been organized (have subdirectories with pkl files)\"\"\"\n",
    "    if not os.path.exists(OBJ_DIR):\n",
    "        return 0\n",
    "    count = 0\n",
    "    for d in os.listdir(OBJ_DIR):\n",
    "        dp = os.path.join(OBJ_DIR, d)\n",
    "        if os.path.isdir(dp) and not d.startswith('.'):\n",
    "            # Check if it has pkl files inside\n",
    "            if any(f.endswith('.pkl') for f in os.listdir(dp)):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "organized_count = count_organized_videos()\n",
    "already_organized = organized_count > 0\n",
    "\n",
    "if already_organized:\n",
    "    print(f'Data already organized: {organized_count} videos in {OBJ_DIR}')\n",
    "    \n",
    "    # Sample check: show first video's structure\n",
    "    sample_dirs = [d for d in os.listdir(OBJ_DIR) \n",
    "                   if os.path.isdir(os.path.join(OBJ_DIR, d)) and not d.startswith('.')][:3]\n",
    "    for sample_video in sample_dirs:\n",
    "        sample_path = os.path.join(OBJ_DIR, sample_video)\n",
    "        pkl_files = sorted([f for f in os.listdir(sample_path) if f.endswith('.pkl')])\n",
    "        print(f'  Sample: \"{sample_video}\" has {len(pkl_files)} frame files')\n",
    "        \n",
    "        # Verify structure of first pkl\n",
    "        if pkl_files:\n",
    "            with open(os.path.join(sample_path, pkl_files[0]), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "            if isinstance(data, dict):\n",
    "                print(f'    Keys: {list(data.keys())}')\n",
    "                if 'feat' in data:\n",
    "                    print(f'    feat shape: {np.array(data[\"feat\"]).shape}')\n",
    "                if 'bbox' in data:\n",
    "                    print(f'    bbox shape: {np.array(data[\"bbox\"]).shape}')\n",
    "\n",
    "else:\n",
    "    print('Organizing object features from Kaggle dataset...')\n",
    "    \n",
    "    if not os.path.exists(KAGGLE_INPUT_PATH):\n",
    "        print(f'ERROR: Kaggle input path not found: {KAGGLE_INPUT_PATH}')\n",
    "        print('Please update KAGGLE_INPUT_PATH to match your dataset location')\n",
    "    else:\n",
    "        # Find all subdirectories containing pkl files\n",
    "        subdirs = []\n",
    "        for d in os.listdir(KAGGLE_INPUT_PATH):\n",
    "            dp = os.path.join(KAGGLE_INPUT_PATH, d)\n",
    "            if os.path.isdir(dp):\n",
    "                subdirs.append(d)\n",
    "        \n",
    "        print(f'Found {len(subdirs)} subdirectories: {subdirs}')\n",
    "        \n",
    "        # Count total pkl files first\n",
    "        all_pkl_files = []\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(KAGGLE_INPUT_PATH, subdir)\n",
    "            pkl_files = [f for f in os.listdir(subdir_path) \n",
    "                        if f.endswith('.pkl') and not f.startswith('._')]\n",
    "            for pf in pkl_files:\n",
    "                all_pkl_files.append((subdir, pf))\n",
    "        \n",
    "        print(f'Total pkl files to process: {len(all_pkl_files)}')\n",
    "        \n",
    "        video_count = 0\n",
    "        frame_count = 0\n",
    "        errors = []\n",
    "        \n",
    "        # Process with progress bar\n",
    "        for subdir, pkl_file in tqdm(all_pkl_files, desc='Organizing'):\n",
    "            video_id = pkl_file[:-4]  # Remove '.pkl' extension\n",
    "            video_dir = os.path.join(OBJ_DIR, video_id)\n",
    "            src_file = os.path.join(KAGGLE_INPUT_PATH, subdir, pkl_file)\n",
    "            \n",
    "            try:\n",
    "                # Skip if already processed\n",
    "                if os.path.exists(video_dir) and os.listdir(video_dir):\n",
    "                    video_count += 1\n",
    "                    continue\n",
    "                \n",
    "                os.makedirs(video_dir, exist_ok=True)\n",
    "                \n",
    "                # Load the pkl file\n",
    "                with open(src_file, 'rb') as f:\n",
    "                    data = pkl.load(f)\n",
    "                \n",
    "                # Determine structure and extract features\n",
    "                if isinstance(data, dict):\n",
    "                    feats = data.get('feat', data.get('features'))\n",
    "                    bboxes = data.get('bbox', data.get('boxes', data.get('box')))\n",
    "                    img_w = data.get('img_w', 640)\n",
    "                    img_h = data.get('img_h', 480)\n",
    "                elif isinstance(data, (tuple, list)) and len(data) >= 2:\n",
    "                    feats, bboxes = data[0], data[1]\n",
    "                    img_w, img_h = 640, 480\n",
    "                else:\n",
    "                    errors.append(f'{video_id}: Unknown pkl structure type={type(data)}')\n",
    "                    continue\n",
    "                \n",
    "                # Validate data\n",
    "                if feats is None or bboxes is None:\n",
    "                    errors.append(f'{video_id}: feats or bboxes is None')\n",
    "                    continue\n",
    "                \n",
    "                # Convert to numpy\n",
    "                if not isinstance(feats, np.ndarray):\n",
    "                    feats = np.array(feats)\n",
    "                if not isinstance(bboxes, np.ndarray):\n",
    "                    bboxes = np.array(bboxes)\n",
    "                \n",
    "                # Determine number of frames based on shape\n",
    "                # Expected: [num_frames, num_objects, feat_dim] or [num_objects, feat_dim]\n",
    "                if len(feats.shape) == 3:\n",
    "                    num_frames = feats.shape[0]\n",
    "                elif len(feats.shape) == 2:\n",
    "                    # Single frame case\n",
    "                    feats = feats[np.newaxis, ...]\n",
    "                    bboxes = bboxes[np.newaxis, ...]\n",
    "                    num_frames = 1\n",
    "                else:\n",
    "                    errors.append(f'{video_id}: Unexpected feat shape {feats.shape}')\n",
    "                    continue\n",
    "                \n",
    "                # Validate bbox shape matches\n",
    "                if bboxes.shape[0] != num_frames:\n",
    "                    errors.append(f'{video_id}: bbox frames {bboxes.shape[0]} != feat frames {num_frames}')\n",
    "                    continue\n",
    "                \n",
    "                # Split into individual frame pkl files\n",
    "                for frame_idx in range(num_frames):\n",
    "                    frame_data = {\n",
    "                        'feat': feats[frame_idx].astype(np.float32),\n",
    "                        'bbox': bboxes[frame_idx].astype(np.float32),\n",
    "                        'img_w': int(img_w),\n",
    "                        'img_h': int(img_h)\n",
    "                    }\n",
    "                    \n",
    "                    frame_pkl_path = os.path.join(video_dir, f'{frame_idx}.pkl')\n",
    "                    with open(frame_pkl_path, 'wb') as f:\n",
    "                        pkl.dump(frame_data, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "                    frame_count += 1\n",
    "                \n",
    "                video_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                errors.append(f'{video_id}: {str(e)}')\n",
    "                # Clean up failed directory\n",
    "                if os.path.exists(video_dir):\n",
    "                    import shutil\n",
    "                    shutil.rmtree(video_dir, ignore_errors=True)\n",
    "        \n",
    "        # Summary\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'ORGANIZATION COMPLETE')\n",
    "        print(f'{\"=\"*50}')\n",
    "        print(f'  Videos processed: {video_count}')\n",
    "        print(f'  Total frames: {frame_count}')\n",
    "        print(f'  Output directory: {OBJ_DIR}')\n",
    "        \n",
    "        if errors:\n",
    "            print(f'\\n  Errors encountered: {len(errors)}')\n",
    "            for err in errors[:10]:\n",
    "                print(f'    - {err}')\n",
    "            if len(errors) > 10:\n",
    "                print(f'    ... and {len(errors) - 10} more errors')\n",
    "        \n",
    "        # Verify a sample\n",
    "        print(f'\\nVerification sample:')\n",
    "        sample_dirs = [d for d in os.listdir(OBJ_DIR) \n",
    "                       if os.path.isdir(os.path.join(OBJ_DIR, d))][:2]\n",
    "        for sd in sample_dirs:\n",
    "            sp = os.path.join(OBJ_DIR, sd)\n",
    "            files = os.listdir(sp)\n",
    "            print(f'  {sd}: {len(files)} files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Config\n",
    "print('=== CELL 6: Config ===')\n",
    "\n",
    "RUN_TRAINING = True\n",
    "HF_REPO_ID = 'DanielQ07/transtr-causalvid-weights'\n",
    "HF_MODEL_FILENAME = 'best_model.ckpt'\n",
    "\n",
    "class Config:\n",
    "    video_feature_root = '/kaggle/input/YOUR_VIT_DATASET'\n",
    "    object_feature_path = OBJ_DIR\n",
    "    sample_list_path = os.path.join(os.getcwd(), '..', 'data', 'vqa', 'causal', 'anno')\n",
    "    split_dir_txt = os.path.join(os.getcwd(), '..', 'data', 'splits')\n",
    "    \n",
    "    topK_frame = 16; objs = 20; frames = 16\n",
    "    select_frames = 5; topK_obj = 12\n",
    "    frame_feat_dim = 1024; obj_feat_dim = 2053\n",
    "    d_model = 768; word_dim = 768; nheads = 8\n",
    "    num_encoder_layers = 2; num_decoder_layers = 2\n",
    "    normalize_before = True; activation = 'gelu'\n",
    "    dropout = 0.3; encoder_dropout = 0.3\n",
    "    text_encoder_type = 'microsoft/deberta-base'\n",
    "    freeze_text_encoder = False; text_encoder_lr = 1e-5; text_pool_mode = 1\n",
    "    bs = 8; lr = 1e-5; epoch = 20; gpu = 0\n",
    "    patience = 5; gamma = 0.1; decay = 1e-4; n_query = 5\n",
    "    hard_eval = False; pos_ratio = 1.0; neg_ratio = 1.0; a = 1.0\n",
    "    use_amp = True; num_workers = 4\n",
    "\n",
    "args = Config()\n",
    "set_gpu_devices(args.gpu)\n",
    "set_seed(999)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Create Datasets with Verification\n",
    "print('=== CELL 7: Datasets ===')\n",
    "\n",
    "# Configuration for limiting train samples (set to None for no limit)\n",
    "MAX_TRAIN_SAMPLES = 1000  # Change this to limit training videos, or None for all\n",
    "\n",
    "# Create datasets with detailed logging\n",
    "print('\\n--- Creating TRAIN dataset ---')\n",
    "train_ds = VideoQADataset(\n",
    "    split='train', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=MAX_TRAIN_SAMPLES,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('\\n--- Creating VAL dataset ---')\n",
    "val_ds = VideoQADataset(\n",
    "    split='val', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=None,  # Don't limit val/test\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('\\n--- Creating TEST dataset ---')\n",
    "test_ds = VideoQADataset(\n",
    "    split='test', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=None,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, args.bs, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, args.bs, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, args.bs, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "# Summary\n",
    "print('\\n' + '='*60)\n",
    "print('DATASET SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Train: {len(train_ds)} samples -> {len(train_loader)} batches')\n",
    "print(f'Val:   {len(val_ds)} samples -> {len(val_loader)} batches')\n",
    "print(f'Test:  {len(test_ds)} samples -> {len(test_loader)} batches')\n",
    "print('='*60)\n",
    "\n",
    "# Quick sanity check - load one batch\n",
    "if len(train_ds) > 0:\n",
    "    print('\\nSanity check: Loading first batch...')\n",
    "    try:\n",
    "        ff, of, qns, ans, ans_id, keys = next(iter(train_loader))\n",
    "        print(f'  ViT features: {ff.shape}')  # Expected: [batch, topK_frame, feat_dim]\n",
    "        print(f'  Object features: {of.shape}')  # Expected: [batch, topK_frame, obj_num, 2053]\n",
    "        print(f'  Answer IDs: {ans_id}')\n",
    "        print('Sanity check PASSED!')\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Model\n",
    "print('=== CELL 8: Model ===')\n",
    "cfg = {k: v for k, v in Config.__dict__.items() if not k.startswith('_')}\n",
    "cfg['device'] = device\n",
    "cfg['topK_frame'] = args.select_frames\n",
    "model = VideoQAmodel(**cfg)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=args.gamma, patience=args.patience)\n",
    "model.to(device)\n",
    "xe = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
    "save_path = os.path.join(MODEL_DIR, HF_MODEL_FILENAME)\n",
    "print(f'Model: {sum(p.numel() for p in model.parameters())/1e6:.1f}M params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: Training\n",
    "print('=== CELL 9: Training ===')\n",
    "best_acc = 0\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    for ep in range(1, args.epoch + 1):\n",
    "        loss, acc = train_epoch(model, optimizer, train_loader, xe, device, scaler)\n",
    "        val_acc = eval_epoch(model, val_loader, device)\n",
    "        scheduler.step(val_acc)\n",
    "        print(f'Ep {ep}: Loss={loss:.4f}, Train={acc:.1f}%, Val={val_acc:.1f}%')\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'  Saved!')\n",
    "    print(f'\\nBest Val: {best_acc:.1f}%')\n",
    "    try:\n",
    "        api = HfApi()\n",
    "        api.create_repo(repo_id=HF_REPO_ID, repo_type='model', exist_ok=True)\n",
    "        api.upload_file(path_or_fileobj=save_path, path_in_repo=HF_MODEL_FILENAME, repo_id=HF_REPO_ID, repo_type='model')\n",
    "        print('Uploaded!')\n",
    "    except Exception as e:\n",
    "        print(f'Upload failed: {e}')\n",
    "else:\n",
    "    print('Skipping training (RUN_TRAINING=False)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Detailed Evaluation Function (with ALL score)\n",
    "print('=== CELL 10: Evaluation Functions ===')\n",
    "\n",
    "def run_detailed_evaluation(model, loader, device, split_name='test', save_file='failure_cases.json'):\n",
    "    # Load weights\n",
    "    loaded = False\n",
    "    if RUN_TRAINING:\n",
    "        if os.path.exists(save_path):\n",
    "            model.load_state_dict(torch.load(save_path))\n",
    "            print(f'Loaded Locally Trained Model: {save_path}')\n",
    "            loaded = True\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Downloading {HF_MODEL_FILENAME} from {HF_REPO_ID}...')\n",
    "            local_model_path = hf_hub_download(repo_id=HF_REPO_ID, filename=HF_MODEL_FILENAME, local_dir=MODEL_DIR)\n",
    "            model.load_state_dict(torch.load(local_model_path))\n",
    "            print(f'Loaded HF Model: {local_model_path}')\n",
    "            loaded = True\n",
    "        except Exception as e:\n",
    "            print(f'Could not download model: {e}')\n",
    "\n",
    "    model.eval()\n",
    "    vid_results = {}\n",
    "    failures = []\n",
    "    \n",
    "    type_map = {\n",
    "        'descriptive': 'd', 'explanatory': 'e',\n",
    "        'predictive': 'p', 'predictive_reason': 'pr',\n",
    "        'counterfactual': 'c', 'counterfactual_reason': 'cr'\n",
    "    }\n",
    "    \n",
    "    print(f'\\nRunning Detailed Evaluation on {split_name.upper()} Set...')\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            vid_frame_feat, vid_obj_feat, qns_word, ans_word, ans_id, qns_keys = batch\n",
    "            vid_frame_feat = vid_frame_feat.to(device)\n",
    "            vid_obj_feat = vid_obj_feat.to(device)\n",
    "            out = model(vid_frame_feat, vid_obj_feat, qns_word, ans_word)\n",
    "            preds = out.argmax(dim=-1).cpu().numpy()\n",
    "            targets = ans_id.numpy()\n",
    "            \n",
    "            for i, qkey in enumerate(qns_keys):\n",
    "                found_type = None\n",
    "                vid_id = None\n",
    "                for t_str, t_short in type_map.items():\n",
    "                    if qkey.endswith('_' + t_str):\n",
    "                        found_type = t_short\n",
    "                        vid_id = qkey[:-(len(t_str)+1)]\n",
    "                        break\n",
    "                if not found_type:\n",
    "                    continue\n",
    "                if vid_id not in vid_results:\n",
    "                    vid_results[vid_id] = {}\n",
    "                \n",
    "                is_correct = (preds[i] == targets[i])\n",
    "                vid_results[vid_id][found_type] = {'correct': is_correct}\n",
    "                \n",
    "                if not is_correct:\n",
    "                    failures.append({\n",
    "                        'video_id': vid_id,\n",
    "                        'type': found_type,\n",
    "                        'question': qns_word[i],\n",
    "                        'pred': int(preds[i]),\n",
    "                        'ground_truth': int(targets[i])\n",
    "                    })\n",
    "\n",
    "    # Calculate stats (including ALL)\n",
    "    stats = {k: {'correct': 0, 'total': 0} for k in ['d', 'e', 'p', 'pr', 'c', 'cr', 'par', 'car', 'all']}\n",
    "    for vid, res in vid_results.items():\n",
    "        for t in ['d', 'e', 'p', 'pr', 'c', 'cr']:\n",
    "            if t in res:\n",
    "                stats[t]['total'] += 1\n",
    "                stats['all']['total'] += 1\n",
    "                if res[t]['correct']:\n",
    "                    stats[t]['correct'] += 1\n",
    "                    stats['all']['correct'] += 1\n",
    "        # Combined PAR\n",
    "        if 'p' in res and 'pr' in res:\n",
    "            stats['par']['total'] += 1\n",
    "            if res['p']['correct'] and res['pr']['correct']:\n",
    "                stats['par']['correct'] += 1\n",
    "        # Combined CAR\n",
    "        if 'c' in res and 'cr' in res:\n",
    "            stats['car']['total'] += 1\n",
    "            if res['c']['correct'] and res['cr']['correct']:\n",
    "                stats['car']['correct'] += 1\n",
    "\n",
    "    # Print results with ALL\n",
    "    labels, accs = [], []\n",
    "    print(f\"\\n{'Type':<6} {'Acc %':<10} {'Cor':<6} {'Tot':<6}\")\n",
    "    print('-' * 35)\n",
    "    for k in ['d', 'e', 'p', 'pr', 'par', 'c', 'cr', 'car']:\n",
    "        s = stats[k]\n",
    "        acc = s['correct'] / s['total'] * 100 if s['total'] > 0 else 0\n",
    "        print(f\"{k.upper():<6} {acc:<10.2f} {s['correct']:<6} {s['total']:<6}\")\n",
    "        if s['total'] > 0:\n",
    "            labels.append(k.upper())\n",
    "            accs.append(acc)\n",
    "    print('-' * 35)\n",
    "    # Print ALL score\n",
    "    all_s = stats['all']\n",
    "    all_acc = all_s['correct'] / all_s['total'] * 100 if all_s['total'] > 0 else 0\n",
    "    print(f\"{'ALL':<6} {all_acc:<10.2f} {all_s['correct']:<6} {all_s['total']:<6}\")\n",
    "    print('=' * 35)\n",
    "    labels.append('ALL')\n",
    "    accs.append(all_acc)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    colors = ['steelblue'] * (len(labels) - 1) + ['darkgreen']\n",
    "    bars = plt.bar(labels, accs, color=colors)\n",
    "    plt.ylim(0, 105)\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Performance by Question Type ({split_name.upper()} Set)')\n",
    "    for bar in bars:\n",
    "        y = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, y + 1, f'{y:.1f}', ha='center', va='bottom')\n",
    "    plt.axhline(y=20, color='gray', linestyle='--', alpha=0.5, label='Random (20%)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{split_name}_results.png', dpi=150)\n",
    "    print(f'\\nSaved: {split_name}_results.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Save failures\n",
    "    failure_file = f'{split_name}_{save_file}'\n",
    "    with open(failure_file, 'w') as f:\n",
    "        json.dump(failures, f, indent=4)\n",
    "    print(f'Saved {len(failures)} failure cases to {failure_file}')\n",
    "    \n",
    "    return stats, failures\n",
    "\n",
    "print('Evaluation function defined (with ALL score)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: Evaluate on TEST set\n",
    "print('=== CELL 11: TEST Set Evaluation ===')\n",
    "test_stats, test_failures = run_detailed_evaluation(model, test_loader, device, split_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: Evaluate on VALIDATION set\n",
    "print('=== CELL 12: VALIDATION Set Evaluation ===')\n",
    "val_stats, val_failures = run_detailed_evaluation(model, val_loader, device, split_name='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 13: Summary CSV\n",
    "print('=== CELL 13: Summary ===')\n",
    "\n",
    "type_keys = ['d', 'e', 'p', 'pr', 'par', 'c', 'cr', 'car', 'all']\n",
    "type_names = ['D', 'E', 'P', 'PR', 'PAR', 'C', 'CR', 'CAR', 'ALL']\n",
    "\n",
    "summary_data = []\n",
    "for k, name in zip(type_keys, type_names):\n",
    "    v = val_stats[k]\n",
    "    t = test_stats[k]\n",
    "    summary_data.append({\n",
    "        'Type': name,\n",
    "        'Val_Correct': v['correct'],\n",
    "        'Val_Total': v['total'],\n",
    "        'Val_Acc%': round(v['correct']/v['total']*100, 2) if v['total'] > 0 else 0,\n",
    "        'Test_Correct': t['correct'],\n",
    "        'Test_Total': t['total'],\n",
    "        'Test_Acc%': round(t['correct']/t['total']*100, 2) if t['total'] > 0 else 0\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "df.to_csv('evaluation_summary.csv', index=False)\n",
    "print('Saved: evaluation_summary.csv\\n')\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
