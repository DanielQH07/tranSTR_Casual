{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Environment Setup (Kaggle)\n",
                "This cell clones the repository and sets the working directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "# --- Git Clone & Setup ---\n",
                "REPO_URL = \"https://github.com/DanielQH07/tranSTR_Casual.git\" \n",
                "REPO_NAME = \"tranSTR_Casual\"\n",
                "BRANCH = \"main\" \n",
                "\n",
                "if not os.path.exists(REPO_NAME):\n",
                "    print(f\"Cloning {REPO_URL}...\")\n",
                "    !git clone {REPO_URL}\n",
                "else:\n",
                "    print(\"Repo already exists.\")\n",
                "\n",
                "# Change Directory to the repo root \n",
                "if os.path.basename(os.getcwd()) != REPO_NAME:\n",
                "    try:\n",
                "        target_dir = os.path.join(os.getcwd(), REPO_NAME, \"causalvid\")\n",
                "        if os.path.exists(target_dir):\n",
                "             os.chdir(target_dir)\n",
                "        elif os.path.exists(REPO_NAME):\n",
                "             os.chdir(REPO_NAME)\n",
                "        \n",
                "        print(f\"Changed directory to: {os.getcwd()}\")\n",
                "    except Exception as e:\n",
                "             print(f\"Could not set working directory: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Install & Login Hugging Face ---\n",
                "# Requires for uploading/downloading weights\n",
                "!pip install huggingface_hub\n",
                "from huggingface_hub import notebook_login, HfApi, hf_hub_download, list_repo_tree\n",
                "\n",
                "print(\"Please login to Hugging Face to enable model upload/download.\")\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import argparse\n",
                "from torch.utils.data import DataLoader\n",
                "from utils.util import set_seed, set_gpu_devices, save_file\n",
                "from networks.model import VideoQAmodel\n",
                "from DataLoader import VideoQADataset\n",
                "import torch.nn as nn\n",
                "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
                "from utils.logger import logger\n",
                "\n",
                "from train import train, eval, predict\n",
                "\n",
                "print(\"Libraries imported successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Data & Pipeline Configuration\n",
                "Configure whether to Train or just Test, and where to store Model Weights on HF."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- WORKFLOW CONTROL ---\n",
                "RUN_TRAINING = True   # Set to False to skip training and load weights from HF\n",
                "HF_REPO_ID = \"DanielQ07/transtr-causalvid-weights\" # Your Model Repo ID\n",
                "HF_MODEL_FILENAME = \"best_model_causalvid.ckpt\" # Name of the file on HF\n",
                "\n",
                "# --- Data Configuration ---\n",
                "HF_DATASET_ID = \"DanielQ07/kltn\"\n",
                "HF_SHARD_FOLDER = \"shards\" # Folder inside the dataset containing tar.gz files\n",
                "\n",
                "import os\n",
                "import tarfile\n",
                "import shutil\n",
                "import urllib.request\n",
                "\n",
                "BASE_WORK_DIR = \"/kaggle/working\" if os.path.exists(\"/kaggle/working\") else os.getcwd()\n",
                "OBJ_DIR = os.path.join(BASE_WORK_DIR, \"features\", \"objects\")\n",
                "ANNO_DIR = os.path.join(BASE_WORK_DIR, \"data\", \"annotations\") \n",
                "MODEL_DIR = os.path.join(BASE_WORK_DIR, \"models\")\n",
                "\n",
                "for d in [OBJ_DIR, ANNO_DIR, MODEL_DIR]:\n",
                "    if not os.path.exists(d): os.makedirs(d)\n",
                "\n",
                "print(f\"Object Features will be in: {OBJ_DIR}\")\n",
                "\n",
                "# --- 1. Download & Extract Shards ---\n",
                "# We only proceed if OBJ_DIR seems empty (no video folders)\n",
                "# Heuristic: check if any subdirectory exists\n",
                "has_subdirs = any(os.path.isdir(os.path.join(OBJ_DIR, i)) for i in os.listdir(OBJ_DIR))\n",
                "\n",
                "if not has_subdirs:\n",
                "    print(f\"Fetching shards from {HF_DATASET_ID}/{HF_SHARD_FOLDER}...\")\n",
                "    try:\n",
                "        # List files in the shards folder\n",
                "        files = list_repo_tree(repo_id=HF_DATASET_ID, repo_type=\"dataset\", path_in_repo=HF_SHARD_FOLDER)\n",
                "        tar_files = [f.path for f in files if f.path.endswith('.tar.gz')]\n",
                "        print(f\"Found {len(tar_files)} shards to process.\")\n",
                "        \n",
                "        for remote_path in tar_files:\n",
                "            filename = os.path.basename(remote_path)\n",
                "            print(f\"Downloading & Extracting {filename}...\")\n",
                "            \n",
                "            # Download (caches implicitly, but we copy/link/use path)\n",
                "            local_tar = hf_hub_download(repo_id=HF_DATASET_ID, filename=remote_path, repo_type=\"dataset\", local_dir=BASE_WORK_DIR)\n",
                "            \n",
                "            # Extract to OBJ_DIR\n",
                "            with tarfile.open(local_tar, \"r:gz\") as tar:\n",
                "                tar.extractall(path=OBJ_DIR)\n",
                "            \n",
                "            # Cleanup Tar\n",
                "            os.remove(local_tar)\n",
                "\n",
                "        print(\"Download & Extraction Complete. Checking Structure...\")\n",
                "        # --- Flatten Directory Logic ---\n",
                "        # Structure might be OBJ_DIR/shard_xxxxx/video_id\n",
                "        # We want OBJ_DIR/video_id\n",
                "        moved_count = 0\n",
                "        for item in os.listdir(OBJ_DIR):\n",
                "            item_path = os.path.join(OBJ_DIR, item)\n",
                "            if os.path.isdir(item_path) and (item.startswith(\"shard_\") or item.startswith(\"train_\") or item.startswith(\"val_\")):\n",
                "                # Valid shard folder, move contents up\n",
                "                for sub_item in os.listdir(item_path):\n",
                "                    src_path = os.path.join(item_path, sub_item)\n",
                "                    dst_path = os.path.join(OBJ_DIR, sub_item)\n",
                "                    if not os.path.exists(dst_path):\n",
                "                        shutil.move(src_path, dst_path)\n",
                "                        moved_count += 1\n",
                "                # Remove empty shard folder\n",
                "                os.rmdir(item_path)\n",
                "        \n",
                "        print(f\"Flattened {moved_count} video folders to root of {OBJ_DIR}\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error processing data: {e}\")\n",
                "else:\n",
                "    print(\"Features folder not empty, skipping download.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    # --- PATHS ---\n",
                "    # 1. Video Features (ViT features)\n",
                "    video_feature_root = r\"D:\\KLTN\\TranSTR\\causalvid\\features\\vit\"  \n",
                "    if not os.path.exists(video_feature_root) and os.path.exists(\"/kaggle/input\"):\n",
                "        # Example Kaggle Input path - UPDATE THIS\n",
                "        video_feature_root = \"/kaggle/input/your-dataset-name/features/vit\"\n",
                "\n",
                "    # 2. Object Features \n",
                "    object_feature_path = OBJ_DIR\n",
                "\n",
                "    # 3. Annotations \n",
                "    sample_list_path = r\"D:\\KLTN\\TranSTR\\causalvid\\data\\vqa\\causal\\anno\"\n",
                "    if not os.path.exists(sample_list_path):\n",
                "        repo_anno = os.path.join(os.getcwd(), \"..\", \"data\", \"vqa\", \"causal\", \"anno\")\n",
                "        if os.path.exists(repo_anno):\n",
                "            sample_list_path = repo_anno\n",
                "        else:\n",
                "            sample_list_path = ANNO_DIR\n",
                "\n",
                "    # 4. Splits \n",
                "    split_dir_txt = r\"D:\\KLTN\\TranSTR\\causalvid\\data\\splits\"\n",
                "    if not os.path.exists(split_dir_txt):\n",
                "         repo_split = os.path.join(os.getcwd(), \"..\", \"data\", \"splits\")\n",
                "         if os.path.exists(repo_split):\n",
                "             split_dir_txt = repo_split\n",
                "    \n",
                "    print(f\"Configured Paths:\\n - Video Feat: {video_feature_root}\\n - Object Feat: {object_feature_path}\\n - Anno Path: {sample_list_path}\\n - Split Dir: {split_dir_txt}\")\n",
                "\n",
                "    # Model Params\n",
                "    v = \"v1\"\n",
                "    bs = 8 \n",
                "    lr = 1e-4\n",
                "    epoch = 20\n",
                "    gpu = 0\n",
                "    dropout = 0.3\n",
                "    encoder_dropout = 0.3\n",
                "    patience = 5\n",
                "    gamma = 0.1\n",
                "    decay = 1e-4\n",
                "    \n",
                "    # Dataset Params\n",
                "    dataset = 'causal-vid'\n",
                "    objs = 10 \n",
                "    n_query = 5\n",
                "    \n",
                "    # Transformer\n",
                "    d_model = 512\n",
                "    word_dim = 768\n",
                "    topK_frame = 20\n",
                "    topK_obj = 10\n",
                "    num_encoder_layers = 2\n",
                "    num_decoder_layers = 2\n",
                "    nheads = 8\n",
                "    normalize_before = True\n",
                "    activation = 'gelu'\n",
                "    \n",
                "    # Text Encoder\n",
                "    text_encoder_lr = 1e-5\n",
                "    freeze_text_encoder = False\n",
                "    text_encoder_type = \"bert-base-uncased\"\n",
                "    text_pool_mode = 1\n",
                "    \n",
                "    # Misc\n",
                "    hard_eval = False\n",
                "    pos_ratio = 1.0\n",
                "    neg_ratio = 1.0\n",
                "    a = 1.0\n",
                "    use_amp = True\n",
                "    num_workers = 2 \n",
                "    frame_feat_dim = 768 \n",
                "    obj_feat_dim = 2048 + 5 \n",
                "\n",
                "args = Config()\n",
                "set_gpu_devices(args.gpu)\n",
                "set_seed(999)\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize DataLoaders\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Initializing Datasets...\")\n",
                "\n",
                "try:\n",
                "    # TRAIN\n",
                "    train_dataset = VideoQADataset(\n",
                "        split='train', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt,\n",
                "        topK_frame=args.topK_frame\n",
                "    )\n",
                "\n",
                "    # VAL\n",
                "    val_dataset = VideoQADataset(\n",
                "        split='val', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt,\n",
                "        topK_frame=args.topK_frame\n",
                "    )\n",
                "\n",
                "    # TEST\n",
                "    test_dataset = VideoQADataset(\n",
                "        split='test', \n",
                "        n_query=args.n_query, \n",
                "        obj_num=args.objs,\n",
                "        sample_list_path=args.sample_list_path,\n",
                "        video_feature_path=args.video_feature_root,\n",
                "        object_feature_path=args.object_feature_path,\n",
                "        split_dir=args.split_dir_txt,\n",
                "        topK_frame=args.topK_frame\n",
                "    )\n",
                "\n",
                "    train_loader = DataLoader(dataset=train_dataset, batch_size=args.bs, shuffle=True, \n",
                "                              num_workers=args.num_workers, pin_memory=True)\n",
                "    val_loader = DataLoader(dataset=val_dataset, batch_size=args.bs, shuffle=False, \n",
                "                            num_workers=args.num_workers, pin_memory=True)\n",
                "    test_loader = DataLoader(dataset=test_dataset, batch_size=args.bs, shuffle=False, \n",
                "                             num_workers=args.num_workers, pin_memory=True)\n",
                "\n",
                "    print(\"\\nDatasets initialized successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"\\nError initializing datasets: {e}\")\n",
                "    import traceback\n",
                "    traceback.print_exc()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Setup\n",
                "Initializing the model logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_dict = {k: v for k, v in Config.__dict__.items() if not k.startswith('__')}\n",
                "config_dict['device'] = device\n",
                "model = VideoQAmodel(**config_dict)\n",
                "\n",
                "param_dicts = [\n",
                "    {\"params\": [p for n, p in model.named_parameters() if \"text_encoder\" not in n and p.requires_grad]},\n",
                "    {\"params\": [p for n, p in model.named_parameters() if \"text_encoder\" in n and p.requires_grad], \"lr\": args.text_encoder_lr}\n",
                "]\n",
                "optimizer = torch.optim.AdamW(params=param_dicts, lr=args.lr, weight_decay=args.decay)\n",
                "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=args.gamma, patience=args.patience, verbose=True)\n",
                "model.to(device)\n",
                "xe = nn.CrossEntropyLoss().to(device)\n",
                "print(\"Model and Optimizer created.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Loop with HF Upload\n",
                "Runs only if `RUN_TRAINING = True`. Saves best model and Uploads to Hugging Face."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_eval_score = 0.0\n",
                "best_epoch = 1\n",
                "save_path = os.path.join(MODEL_DIR, HF_MODEL_FILENAME)\n",
                "\n",
                "# --- Create Scaler ---\n",
                "try:\n",
                "    scaler = torch.amp.GradScaler('cuda', enabled=args.use_amp)\n",
                "    print(\"GradScaler initialized.\")\n",
                "except Exception as e:\n",
                "    # Fallback for older torch versions\n",
                "    scaler = torch.cuda.amp.GradScaler(enabled=args.use_amp)\n",
                "    print(\"GradScaler initialized (fallback).\")\n",
                "\n",
                "if RUN_TRAINING:\n",
                "    print(\"Starting Training Loop...\")\n",
                "    if len(train_loader) > 0:\n",
                "        for epoch in range(1, args.epoch + 1):\n",
                "            print(f\"Epoch {epoch}/{args.epoch}\")\n",
                "            \n",
                "            # Pass scaler to train function\n",
                "            train_loss, train_acc = train(model, optimizer, train_loader, xe, device, use_amp=args.use_amp, scaler=scaler)\n",
                "            \n",
                "            eval_score = eval(model, val_loader, device)\n",
                "            scheduler.step(eval_score)\n",
                "            \n",
                "            print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f} | Val Acc: {eval_score:.2f}\")\n",
                "            \n",
                "            if eval_score > best_eval_score:\n",
                "                best_eval_score = eval_score\n",
                "                best_epoch = epoch\n",
                "                torch.save(model.state_dict(), save_path)\n",
                "                print(f\"  Saved new best model to {save_path}\")\n",
                "    \n",
                "        print(f\"Training Complete. Best Val Acc: {best_eval_score:.2f}\")\n",
                "        \n",
                "        # --- UPLOAD TO HUGGING FACE ---\n",
                "        try:\n",
                "            api = HfApi()\n",
                "            print(f\"Creating/Accessing Repo {HF_REPO_ID}...\")\n",
                "            api.create_repo(repo_id=HF_REPO_ID, repo_type=\"model\", exist_ok=True)\n",
                "            \n",
                "            print(f\"Uploading {save_path} to Hugging Face...\")\n",
                "            api.upload_file(\n",
                "                path_or_fileobj=save_path,\n",
                "                path_in_repo=HF_MODEL_FILENAME,\n",
                "                repo_id=HF_REPO_ID,\n",
                "                repo_type=\"model\"\n",
                "            )\n",
                "            print(\"Upload SUCCESS!\")\n",
                "        except Exception as e:\n",
                "            print(f\"Upload FAILED: {e}\")\n",
                "            \n",
                "    else:\n",
                "        print(\"Train Loader empty. Skipping training.\")\n",
                "else:\n",
                "    print(\"RUN_TRAINING = False. Skipping Training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Detailed Evaluation (Test Mode)\n",
                "If not training, it downloads weights. Then it runs the detailed analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import json\n",
                "\n",
                "def run_detailed_evaluation(model, loader, device, save_file='failure_cases.json'):\n",
                "    # --- LOAD WEIGHTS LOGIC ---\n",
                "    loaded = False\n",
                "    if RUN_TRAINING:\n",
                "        # Use local file if we just trained\n",
                "        if os.path.exists(save_path):\n",
                "            model.load_state_dict(torch.load(save_path))\n",
                "            print(f\"Loaded Locally Trained Model: {save_path}\")\n",
                "            loaded = True\n",
                "    else:\n",
                "        # Download from HF\n",
                "        try:\n",
                "            print(f\"Downloading {HF_MODEL_FILENAME} from {HF_REPO_ID}...\")\n",
                "            local_model_path = hf_hub_download(repo_id=HF_REPO_ID, filename=HF_MODEL_FILENAME, local_dir=MODEL_DIR)\n",
                "            model.load_state_dict(torch.load(local_model_path))\n",
                "            print(f\"Loaded HF Model: {local_model_path}\")\n",
                "            loaded = True\n",
                "        except Exception as e:\n",
                "            print(f\"Could not download model from HF: {e}\\nRunning with random weights (Warning!)\")\n",
                "\n",
                "    \n",
                "    model.eval()\n",
                "    vid_results = {} \n",
                "    failures = []\n",
                "    \n",
                "    type_map = {\n",
                "        'descriptive': 'd',\n",
                "        'explanatory': 'e',\n",
                "        'predictive': 'p',\n",
                "        'predictive_reason': 'pr',\n",
                "        'counterfactual': 'c',\n",
                "        'counterfactual_reason': 'cr'\n",
                "    }\n",
                "    \n",
                "    print(\"Running Detailed Evaluation on Test Set...\")\n",
                "    with torch.no_grad():\n",
                "        for batch in loader:\n",
                "            vid_frame_feat, vid_obj_feat, qns_word, ans_word, ans_id, qns_keys = batch\n",
                "            vid_frame_feat, vid_obj_feat = vid_frame_feat.to(device), vid_obj_feat.to(device)\n",
                "            out = model(vid_frame_feat, vid_obj_feat, qns_word, ans_word)\n",
                "            preds = out.argmax(dim=-1).cpu().numpy()\n",
                "            targets = ans_id.numpy()\n",
                "            \n",
                "            for i, qkey in enumerate(qns_keys):\n",
                "                found_type = None\n",
                "                vid_id = None\n",
                "                for t_str, t_short in type_map.items():\n",
                "                    if qkey.endswith('_' + t_str):\n",
                "                        found_type = t_short\n",
                "                        vid_id = qkey[:-(len(t_str)+1)]\n",
                "                        break\n",
                "                if not found_type: continue\n",
                "                if vid_id not in vid_results: vid_results[vid_id] = {}\n",
                "                \n",
                "                is_correct = (preds[i] == targets[i])\n",
                "                vid_results[vid_id][found_type] = {'correct': is_correct}\n",
                "                \n",
                "                if not is_correct:\n",
                "                    failures.append({\n",
                "                        'video_id': vid_id,\n",
                "                        'type': found_type,\n",
                "                        'question': qns_word[i],\n",
                "                        'pred': int(preds[i]),\n",
                "                        'ground_truth': int(targets[i])\n",
                "                    })\n",
                "\n",
                "    stats = {k: {'correct':0, 'total':0} for k in ['d','e','p','pr','c','cr','par','car']}\n",
                "    for vid, res in vid_results.items():\n",
                "        for t in ['d','e','p','pr','c','cr']:\n",
                "            if t in res:\n",
                "                stats[t]['total'] += 1\n",
                "                if res[t]['correct']: stats[t]['correct'] += 1\n",
                "        # Combined PAR\n",
                "        if 'p' in res and 'pr' in res:\n",
                "            stats['par']['total'] += 1\n",
                "            if res['p']['correct'] and res['pr']['correct']: stats['par']['correct'] += 1\n",
                "        # Combined CAR\n",
                "        if 'c' in res and 'cr' in res:\n",
                "            stats['car']['total'] += 1\n",
                "            if res['c']['correct'] and res['cr']['correct']: stats['car']['correct'] += 1\n",
                "\n",
                "    # Print\n",
                "    labels, accs = [], []\n",
                "    print(f\"{'Type':<6} {'Acc %':<10} {'Cor':<6} {'Tot':<6}\")\n",
                "    print(\"-\"*35)\n",
                "    for k in ['d','e','p','pr','par','c','cr','car']:\n",
                "        s = stats[k]\n",
                "        acc = s['correct']/s['total']*100 if s['total'] > 0 else 0\n",
                "        print(f\"{k.upper():<6} {acc:<10.2f} {s['correct']:<6} {s['total']:<6}\")\n",
                "        if s['total'] > 0: \n",
                "            labels.append(k.upper())\n",
                "            accs.append(acc)\n",
                "\n",
                "    # Plot\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    bars = plt.bar(labels, accs, color='steelblue')\n",
                "    plt.ylim(0, 105)\n",
                "    plt.ylabel('Accuracy (%)')\n",
                "    plt.title('Performance by Question Type')\n",
                "    for bar in bars:\n",
                "        y = bar.get_height()\n",
                "        plt.text(bar.get_x()+bar.get_width()/2, y+1, f\"{y:.1f}\", ha='center', va='bottom')\n",
                "    plt.show()\n",
                "\n",
                "    # Save Failures\n",
                "    with open(save_file, 'w') as f:\n",
                "        json.dump(failures, f, indent=4)\n",
                "    print(f\"\\nSaved {len(failures)} failure cases to {save_file}\")\n",
                "    return stats, failures\n",
                "\n",
                "stats, failures = run_detailed_evaluation(model, test_loader, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "from IPython.display import display\n",
                "\n",
                "print(\"\\n=== Detailed Accuracy Metrics ===\")\n",
                "\n",
                "# Convert stats to DataFrame\n",
                "data = []\n",
                "# Focus on the 6 main types as requested (D, E, P, PR, C, CR)\n",
                "target_types = ['d', 'e', 'p', 'pr', 'c', 'cr']\n",
                "for k in target_types:\n",
                "    if k in stats:\n",
                "        s = stats[k]\n",
                "        acc = s['correct'] / s['total'] * 100 if s['total'] > 0 else 0\n",
                "        data.append({\n",
                "            'Type': k.upper(),\n",
                "            'Total': s['total'],\n",
                "            'Correct': s['correct'],\n",
                "            'Wrong': s['total'] - s['correct'],\n",
                "            'Accuracy (%)': f\"{acc:.2f}\"\n",
                "        })\n",
                "\n",
                "df_results = pd.DataFrame(data)\n",
                "display(df_results) # Pretty print\n",
                "\n",
                "# Visualization of Wrong Answers\n",
                "print(\"\\n=== Failure Distribution (Count of Wrong Answers) ===\")\n",
                "if not df_results.empty:\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    # Need to convert back to numeric for plotting\n",
                "    df_results['Wrong'] = pd.to_numeric(df_results['Wrong'])\n",
                "    sns.barplot(x='Type', y='Wrong', data=df_results, palette='Reds')\n",
                "    plt.title(\"Number of Incorrect Answers by Question Type\")\n",
                "    plt.ylabel(\"Count of Failures\")\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}