{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TranSTR CausalVid - Paper Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Clone\n",
    "import os\n",
    "print('=== CELL 1 ===')\n",
    "if not os.path.exists('tranSTR_Casual'):\n",
    "    !git clone https://github.com/DanielQH07/tranSTR_Casual.git -b origin\n",
    "os.chdir('tranSTR_Casual/causalvid' if os.path.exists('tranSTR_Casual/causalvid') else 'tranSTR_Casual')\n",
    "print(f'CWD: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: HuggingFace\n",
    "print('=== CELL 2 ===')\n",
    "!pip install -q huggingface_hub\n",
    "from huggingface_hub import login, HfApi, hf_hub_download, list_repo_tree\n",
    "# notebook_login()\n",
    "login(token='YOUR_HF_TOKEN') # Replace with your actual token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: Imports\n",
    "print('=== CELL 3: Imports ===')\n",
    "import os, torch, numpy as np, pandas as pd, tarfile, shutil, json\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.util import set_seed, set_gpu_devices\n",
    "from DataLoader import VideoQADataset\n",
    "from networks.model import VideoQAmodel\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3.5: Pre-extract DeBERTa Text Features (Run ONCE before training)\n",
    "print('=== Pre-extracting DeBERTa Text Features ===')\n",
    "print('This will cache all text embeddings - makes training 5-10x faster!')\n",
    "\n",
    "import pickle as pkl\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ============================================\n",
    "# PATHS - UPDATE THESE\n",
    "# ============================================\n",
    "ANNOTATION_PATH = '/kaggle/input/YOUR_ANNOTATION_DATASET'  # Contains video_id/text.json, answer.json\n",
    "SPLIT_DIR = '/kaggle/input/YOUR_SPLITS_DATASET'           # Contains train.pkl, valid.pkl, test.pkl\n",
    "TEXT_FEATURE_PATH = '/kaggle/working/text_features'       # Output directory\n",
    "MODEL_NAME = 'microsoft/deberta-base'\n",
    "\n",
    "os.makedirs(TEXT_FEATURE_PATH, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# LOAD MODEL\n",
    "# ============================================\n",
    "print(f'\\nLoading {MODEL_NAME}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "text_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "text_model.to(device)\n",
    "text_model.eval()\n",
    "print('Model loaded!')\n",
    "\n",
    "# ============================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================\n",
    "def load_split_videos(split_name):\n",
    "    pkl_name = 'valid' if split_name == 'val' else split_name\n",
    "    pkl_path = os.path.join(SPLIT_DIR, f\"{pkl_name}.pkl\")\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pkl.load(f)\n",
    "        return set(data) if isinstance(data, (list, set)) else set(data.keys())\n",
    "    return set()\n",
    "\n",
    "def extract_for_split(split_name, max_videos=None):\n",
    "    print(f'\\n--- {split_name.upper()} ---')\n",
    "    \n",
    "    # Load video IDs\n",
    "    video_ids = load_split_videos(split_name)\n",
    "    if max_videos:\n",
    "        video_ids = set(list(video_ids)[:max_videos])\n",
    "    print(f'Videos: {len(video_ids)}')\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for vid in tqdm(video_ids, desc=f'Extracting {split_name}'):\n",
    "        vp = os.path.join(ANNOTATION_PATH, vid)\n",
    "        tj, aj = os.path.join(vp, \"text.json\"), os.path.join(vp, \"answer.json\")\n",
    "        if not (os.path.exists(tj) and os.path.exists(aj)):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(tj, encoding=\"utf-8\") as f:\n",
    "                td = json.load(f)\n",
    "            \n",
    "            for k in [\"descriptive\", \"explanatory\", \"predictive\", \"counterfactual\"]:\n",
    "                if k in td:\n",
    "                    q = td[k]\n",
    "                    if \"question\" in q and \"answer\" in q:\n",
    "                        qns = q[\"question\"]\n",
    "                        choices = q[\"answer\"]\n",
    "                        texts = [f\"[CLS] {qns} [SEP] {c}\" for c in choices]\n",
    "                        \n",
    "                        tokenized = tokenizer(texts, padding=True, truncation=True, \n",
    "                                             max_length=256, return_tensors='pt').to(device)\n",
    "                        with torch.no_grad():\n",
    "                            out = text_model(**tokenized).last_hidden_state[:, 0, :]  # [5, 768]\n",
    "                        \n",
    "                        features[f\"{vid}_{k}\"] = {\n",
    "                            'cls': out.cpu().numpy().astype(np.float32),\n",
    "                            'question': qns\n",
    "                        }\n",
    "                    \n",
    "                    if k in [\"predictive\", \"counterfactual\"] and \"reason\" in q:\n",
    "                        qns = \"Why?\"\n",
    "                        choices = q[\"reason\"]\n",
    "                        texts = [f\"[CLS] {qns} [SEP] {c}\" for c in choices]\n",
    "                        \n",
    "                        tokenized = tokenizer(texts, padding=True, truncation=True,\n",
    "                                             max_length=256, return_tensors='pt').to(device)\n",
    "                        with torch.no_grad():\n",
    "                            out = text_model(**tokenized).last_hidden_state[:, 0, :]\n",
    "                        \n",
    "                        features[f\"{vid}_{k}_reason\"] = {\n",
    "                            'cls': out.cpu().numpy().astype(np.float32),\n",
    "                            'question': qns\n",
    "                        }\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        if len(features) % 500 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save\n",
    "    output_file = os.path.join(TEXT_FEATURE_PATH, f\"{split_name}_text_features.pkl\")\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pkl.dump(features, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    print(f'Saved: {output_file} ({len(features)} entries)')\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT FOR ALL SPLITS\n",
    "# ============================================\n",
    "# Set max_videos=None for full dataset, or a number for testing\n",
    "train_text = extract_for_split('train', max_videos=None)\n",
    "val_text = extract_for_split('val', max_videos=None)\n",
    "test_text = extract_for_split('test', max_videos=None)\n",
    "\n",
    "# Cleanup\n",
    "del text_model, tokenizer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('TEXT FEATURE EXTRACTION COMPLETE!')\n",
    "print(f'Saved to: {TEXT_FEATURE_PATH}')\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Train/Eval functions (Optimized for cached text features)\n",
    "print('=== CELL 4 ===')\n",
    "\n",
    "def train_epoch(model, optimizer, loader, xe, device, use_cached_text=True):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        ff, of, q, text_feat, ans_id, _ = batch\n",
    "        ff, of, tgt = ff.to(device), of.to(device), ans_id.to(device)\n",
    "        \n",
    "        if use_cached_text and isinstance(text_feat, torch.Tensor):\n",
    "            # Cached text features: [batch, 5, 768]\n",
    "            text_feat = text_feat.to(device)\n",
    "            out = model.forward_cached(ff, of, text_feat)\n",
    "        else:\n",
    "            # Raw text: use DeBERTa (slow)\n",
    "            out = model(ff, of, q, text_feat)\n",
    "        \n",
    "        loss = xe(out, tgt)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct += (out.argmax(-1) == tgt).sum().item()\n",
    "        total += tgt.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total * 100\n",
    "\n",
    "def eval_epoch(model, loader, device, use_cached_text=True):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            ff, of, q, text_feat, ans_id, _ = batch\n",
    "            ff, of = ff.to(device), of.to(device)\n",
    "            \n",
    "            if use_cached_text and isinstance(text_feat, torch.Tensor):\n",
    "                text_feat = text_feat.to(device)\n",
    "                out = model.forward_cached(ff, of, text_feat)\n",
    "            else:\n",
    "                out = model(ff, of, q, text_feat)\n",
    "            \n",
    "            correct += (out.argmax(-1) == ans_id.to(device)).sum().item()\n",
    "            total += ans_id.size(0)\n",
    "    \n",
    "    return correct / total * 100\n",
    "\n",
    "print('Functions defined (cached text support)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5 + 6: Setup Paths & Config\n",
    "print('=== CELL 5+6: Paths & Config ===')\n",
    "\n",
    "# ============================================\n",
    "# KAGGLE INPUT PATHS - UPDATE THESE!\n",
    "# ============================================\n",
    "# ViT video features (folder contains video_id.pt files directly)\n",
    "VIT_FEATURE_PATH = '/kaggle/input/YOUR_VIT_DATASET'  # Contains: video_id.pt files\n",
    "\n",
    "# Object detection features (direct read from Kaggle)\n",
    "OBJ_FEATURE_PATH = '/kaggle/input/object-detection-causal-full'  # Contains: features_node_X/video.pkl\n",
    "\n",
    "# Annotations (folder contains video_id subfolders with text.json, answer.json)\n",
    "ANNOTATION_PATH = '/kaggle/input/YOUR_ANNOTATION_DATASET'  # Contains: video_id/text.json, answer.json\n",
    "\n",
    "# Split files (train.pkl, valid.pkl, test.pkl)\n",
    "SPLIT_DIR = '/kaggle/input/YOUR_SPLITS_DATASET'  # Contains: train.pkl, valid.pkl, test.pkl\n",
    "\n",
    "# ============================================\n",
    "# WORKING DIRECTORIES\n",
    "# ============================================\n",
    "BASE = '/kaggle/working'\n",
    "MODEL_DIR = os.path.join(BASE, 'models')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# VERIFY PATHS\n",
    "# ============================================\n",
    "print('\\n--- Path Verification ---')\n",
    "\n",
    "def verify_path(name, path, expected_sample=None):\n",
    "    if os.path.exists(path):\n",
    "        items = os.listdir(path)[:5]\n",
    "        print(f'✅ {name}')\n",
    "        print(f'   Path: {path}')\n",
    "        print(f'   Sample: {items}')\n",
    "        return True\n",
    "    else:\n",
    "        print(f'❌ {name}: NOT FOUND')\n",
    "        print(f'   Path: {path}')\n",
    "        return False\n",
    "\n",
    "all_ok = True\n",
    "all_ok &= verify_path('ViT Features', VIT_FEATURE_PATH)\n",
    "all_ok &= verify_path('Object Features', OBJ_FEATURE_PATH)\n",
    "all_ok &= verify_path('Annotations', ANNOTATION_PATH)\n",
    "all_ok &= verify_path('Splits', SPLIT_DIR)\n",
    "\n",
    "if not all_ok:\n",
    "    print('\\n⚠️  Please update paths above!')\n",
    "\n",
    "# ============================================\n",
    "# CONFIG\n",
    "# ============================================\n",
    "RUN_TRAINING = True\n",
    "HF_REPO_ID = 'DanielQ07/transtr-causalvid-weights'\n",
    "HF_MODEL_FILENAME = 'best_model.ckpt'\n",
    "\n",
    "class Config:\n",
    "    # Paths from Kaggle input\n",
    "    video_feature_root = VIT_FEATURE_PATH   # video_id.pt files directly\n",
    "    object_feature_path = OBJ_FEATURE_PATH  # features_node_X/video.pkl\n",
    "    sample_list_path = ANNOTATION_PATH      # video_id/text.json, answer.json\n",
    "    split_dir_txt = SPLIT_DIR               # train.pkl, valid.pkl, test.pkl\n",
    "    \n",
    "    # Model architecture (paper config)\n",
    "    topK_frame = 16\n",
    "    objs = 20\n",
    "    frames = 16\n",
    "    select_frames = 5\n",
    "    topK_obj = 12\n",
    "    frame_feat_dim = 1024\n",
    "    obj_feat_dim = 2053\n",
    "    d_model = 768\n",
    "    word_dim = 768\n",
    "    nheads = 8\n",
    "    num_encoder_layers = 2\n",
    "    num_decoder_layers = 2\n",
    "    normalize_before = True\n",
    "    activation = 'gelu'\n",
    "    dropout = 0.3\n",
    "    encoder_dropout = 0.3\n",
    "    \n",
    "    # Text encoder\n",
    "    text_encoder_type = 'microsoft/deberta-base'\n",
    "    freeze_text_encoder = False\n",
    "    text_encoder_lr = 1e-5\n",
    "    text_pool_mode = 1\n",
    "    \n",
    "    # Training\n",
    "    bs = 8\n",
    "    lr = 1e-5\n",
    "    epoch = 20\n",
    "    gpu = 0\n",
    "    patience = 5\n",
    "    gamma = 0.1\n",
    "    decay = 1e-4\n",
    "    n_query = 5\n",
    "    \n",
    "    # Other\n",
    "    hard_eval = False\n",
    "    pos_ratio = 1.0\n",
    "    neg_ratio = 1.0\n",
    "    a = 1.0\n",
    "    use_amp = True\n",
    "    num_workers = 4\n",
    "\n",
    "args = Config()\n",
    "set_gpu_devices(args.gpu)\n",
    "set_seed(999)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\nDevice: {device}')\n",
    "print('Config loaded!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Create Datasets with Cached Text Features\n",
    "print('=== CELL 7: Datasets ===')\n",
    "\n",
    "# Text features path (set to None if not pre-extracted)\n",
    "TEXT_FEATURE_PATH = '/kaggle/working/text_features'  # Output from extract_text_features\n",
    "\n",
    "# Configuration\n",
    "MAX_TRAIN_SAMPLES = 2000  # Set to None for all\n",
    "\n",
    "# Create datasets\n",
    "print('\\n--- Creating TRAIN dataset ---')\n",
    "train_ds = VideoQADataset(\n",
    "    split='train', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=MAX_TRAIN_SAMPLES,\n",
    "    verbose=True,\n",
    "    text_feature_path=TEXT_FEATURE_PATH  # NEW: cached text features\n",
    ")\n",
    "\n",
    "print('\\n--- Creating VAL dataset ---')\n",
    "val_ds = VideoQADataset(\n",
    "    split='val', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=None,\n",
    "    verbose=True,\n",
    "    text_feature_path=TEXT_FEATURE_PATH\n",
    ")\n",
    "\n",
    "print('\\n--- Creating TEST dataset ---')\n",
    "test_ds = VideoQADataset(\n",
    "    split='test', \n",
    "    n_query=args.n_query, \n",
    "    obj_num=args.objs, \n",
    "    sample_list_path=args.sample_list_path, \n",
    "    video_feature_path=args.video_feature_root, \n",
    "    object_feature_path=args.object_feature_path, \n",
    "    split_dir=args.split_dir_txt, \n",
    "    topK_frame=args.topK_frame,\n",
    "    max_samples=None,\n",
    "    verbose=True,\n",
    "    text_feature_path=TEXT_FEATURE_PATH\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_ds, args.bs, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, args.bs, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, args.bs, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "# Summary\n",
    "print('\\n' + '='*60)\n",
    "print('DATASET SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Train: {len(train_ds)} samples -> {len(train_loader)} batches')\n",
    "print(f'Val:   {len(val_ds)} samples -> {len(val_loader)} batches')\n",
    "print(f'Test:  {len(test_ds)} samples -> {len(test_loader)} batches')\n",
    "print(f'Text features: {\"CACHED ✓\" if train_ds.text_features else \"REAL-TIME (slow)\"}')\n",
    "print('='*60)\n",
    "\n",
    "# Sanity check\n",
    "if len(train_ds) > 0:\n",
    "    print('\\nSanity check...')\n",
    "    try:\n",
    "        ff, of, qns, text_feat, ans_id, keys = next(iter(train_loader))\n",
    "        print(f'  ViT: {ff.shape}')\n",
    "        print(f'  Obj: {of.shape}')\n",
    "        if isinstance(text_feat, torch.Tensor):\n",
    "            print(f'  Text (cached): {text_feat.shape}')  # [batch, 5, 768]\n",
    "        else:\n",
    "            print(f'  Text (raw): list of {len(text_feat)} strings')\n",
    "        print('Sanity check PASSED!')\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Model\n",
    "print('=== CELL 8: Model ===')\n",
    "cfg = {k: v for k, v in Config.__dict__.items() if not k.startswith('_')}\n",
    "cfg['device'] = device\n",
    "cfg['topK_frame'] = args.select_frames\n",
    "model = VideoQAmodel(**cfg)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=args.gamma, patience=args.patience)\n",
    "model.to(device)\n",
    "xe = nn.CrossEntropyLoss()\n",
    "#scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
    "save_path = os.path.join(MODEL_DIR, HF_MODEL_FILENAME)\n",
    "print(f'Model: {sum(p.numel() for p in model.parameters())/1e6:.1f}M params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: Training\n",
    "print('=== CELL 9: Training ===')\n",
    "best_acc = 0\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    for ep in range(1, args.epoch + 1):\n",
    "        loss, acc = train_epoch(model, optimizer, train_loader, xe, device)\n",
    "        val_acc = eval_epoch(model, val_loader, device)\n",
    "        scheduler.step(val_acc)\n",
    "        print(f'Ep {ep}: Loss={loss:.4f}, Train={acc:.1f}%, Val={val_acc:.1f}%')\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'  Saved!')\n",
    "    print(f'\\nBest Val: {best_acc:.1f}%')\n",
    "    try:\n",
    "        api = HfApi()\n",
    "        api.create_repo(repo_id=HF_REPO_ID, repo_type='model', exist_ok=True)\n",
    "        api.upload_file(path_or_fileobj=save_path, path_in_repo=HF_MODEL_FILENAME, repo_id=HF_REPO_ID, repo_type='model')\n",
    "        print('Uploaded!')\n",
    "    except Exception as e:\n",
    "        print(f'Upload failed: {e}')\n",
    "else:\n",
    "    print('Skipping training (RUN_TRAINING=False)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Detailed Evaluation Function (with ALL score)\n",
    "print('=== CELL 10: Evaluation Functions ===')\n",
    "\n",
    "def run_detailed_evaluation(model, loader, device, split_name='test', save_file='failure_cases.json'):\n",
    "    # Load weights\n",
    "    loaded = False\n",
    "    if RUN_TRAINING:\n",
    "        if os.path.exists(save_path):\n",
    "            model.load_state_dict(torch.load(save_path))\n",
    "            print(f'Loaded Locally Trained Model: {save_path}')\n",
    "            loaded = True\n",
    "    else:\n",
    "        try:\n",
    "            print(f'Downloading {HF_MODEL_FILENAME} from {HF_REPO_ID}...')\n",
    "            local_model_path = hf_hub_download(repo_id=HF_REPO_ID, filename=HF_MODEL_FILENAME, local_dir=MODEL_DIR)\n",
    "            model.load_state_dict(torch.load(local_model_path))\n",
    "            print(f'Loaded HF Model: {local_model_path}')\n",
    "            loaded = True\n",
    "        except Exception as e:\n",
    "            print(f'Could not download model: {e}')\n",
    "\n",
    "    model.eval()\n",
    "    vid_results = {}\n",
    "    failures = []\n",
    "    \n",
    "    type_map = {\n",
    "        'descriptive': 'd', 'explanatory': 'e',\n",
    "        'predictive': 'p', 'predictive_reason': 'pr',\n",
    "        'counterfactual': 'c', 'counterfactual_reason': 'cr'\n",
    "    }\n",
    "    \n",
    "    print(f'\\nRunning Detailed Evaluation on {split_name.upper()} Set...')\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            vid_frame_feat, vid_obj_feat, qns_word, ans_word, ans_id, qns_keys = batch\n",
    "            vid_frame_feat = vid_frame_feat.to(device)\n",
    "            vid_obj_feat = vid_obj_feat.to(device)\n",
    "            out = model(vid_frame_feat, vid_obj_feat, qns_word, ans_word)\n",
    "            preds = out.argmax(dim=-1).cpu().numpy()\n",
    "            targets = ans_id.numpy()\n",
    "            \n",
    "            for i, qkey in enumerate(qns_keys):\n",
    "                found_type = None\n",
    "                vid_id = None\n",
    "                for t_str, t_short in type_map.items():\n",
    "                    if qkey.endswith('_' + t_str):\n",
    "                        found_type = t_short\n",
    "                        vid_id = qkey[:-(len(t_str)+1)]\n",
    "                        break\n",
    "                if not found_type:\n",
    "                    continue\n",
    "                if vid_id not in vid_results:\n",
    "                    vid_results[vid_id] = {}\n",
    "                \n",
    "                is_correct = (preds[i] == targets[i])\n",
    "                vid_results[vid_id][found_type] = {'correct': is_correct}\n",
    "                \n",
    "                if not is_correct:\n",
    "                    failures.append({\n",
    "                        'video_id': vid_id,\n",
    "                        'type': found_type,\n",
    "                        'question': qns_word[i],\n",
    "                        'pred': int(preds[i]),\n",
    "                        'ground_truth': int(targets[i])\n",
    "                    })\n",
    "\n",
    "    # Calculate stats (including ALL)\n",
    "    stats = {k: {'correct': 0, 'total': 0} for k in ['d', 'e', 'p', 'pr', 'c', 'cr', 'par', 'car', 'all']}\n",
    "    for vid, res in vid_results.items():\n",
    "        for t in ['d', 'e', 'p', 'pr', 'c', 'cr']:\n",
    "            if t in res:\n",
    "                stats[t]['total'] += 1\n",
    "                stats['all']['total'] += 1\n",
    "                if res[t]['correct']:\n",
    "                    stats[t]['correct'] += 1\n",
    "                    stats['all']['correct'] += 1\n",
    "        # Combined PAR\n",
    "        if 'p' in res and 'pr' in res:\n",
    "            stats['par']['total'] += 1\n",
    "            if res['p']['correct'] and res['pr']['correct']:\n",
    "                stats['par']['correct'] += 1\n",
    "        # Combined CAR\n",
    "        if 'c' in res and 'cr' in res:\n",
    "            stats['car']['total'] += 1\n",
    "            if res['c']['correct'] and res['cr']['correct']:\n",
    "                stats['car']['correct'] += 1\n",
    "\n",
    "    # Print results with ALL\n",
    "    labels, accs = [], []\n",
    "    print(f\"\\n{'Type':<6} {'Acc %':<10} {'Cor':<6} {'Tot':<6}\")\n",
    "    print('-' * 35)\n",
    "    for k in ['d', 'e', 'p', 'pr', 'par', 'c', 'cr', 'car']:\n",
    "        s = stats[k]\n",
    "        acc = s['correct'] / s['total'] * 100 if s['total'] > 0 else 0\n",
    "        print(f\"{k.upper():<6} {acc:<10.2f} {s['correct']:<6} {s['total']:<6}\")\n",
    "        if s['total'] > 0:\n",
    "            labels.append(k.upper())\n",
    "            accs.append(acc)\n",
    "    print('-' * 35)\n",
    "    # Print ALL score\n",
    "    all_s = stats['all']\n",
    "    all_acc = all_s['correct'] / all_s['total'] * 100 if all_s['total'] > 0 else 0\n",
    "    print(f\"{'ALL':<6} {all_acc:<10.2f} {all_s['correct']:<6} {all_s['total']:<6}\")\n",
    "    print('=' * 35)\n",
    "    labels.append('ALL')\n",
    "    accs.append(all_acc)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    colors = ['steelblue'] * (len(labels) - 1) + ['darkgreen']\n",
    "    bars = plt.bar(labels, accs, color=colors)\n",
    "    plt.ylim(0, 105)\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Performance by Question Type ({split_name.upper()} Set)')\n",
    "    for bar in bars:\n",
    "        y = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, y + 1, f'{y:.1f}', ha='center', va='bottom')\n",
    "    plt.axhline(y=20, color='gray', linestyle='--', alpha=0.5, label='Random (20%)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{split_name}_results.png', dpi=150)\n",
    "    print(f'\\nSaved: {split_name}_results.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Save failures\n",
    "    failure_file = f'{split_name}_{save_file}'\n",
    "    with open(failure_file, 'w') as f:\n",
    "        json.dump(failures, f, indent=4)\n",
    "    print(f'Saved {len(failures)} failure cases to {failure_file}')\n",
    "    \n",
    "    return stats, failures\n",
    "\n",
    "print('Evaluation function defined (with ALL score)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: Evaluate on TEST set\n",
    "print('=== CELL 11: TEST Set Evaluation ===')\n",
    "test_stats, test_failures = run_detailed_evaluation(model, test_loader, device, split_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: Evaluate on VALIDATION set\n",
    "print('=== CELL 12: VALIDATION Set Evaluation ===')\n",
    "val_stats, val_failures = run_detailed_evaluation(model, val_loader, device, split_name='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 13: Summary CSV\n",
    "print('=== CELL 13: Summary ===')\n",
    "\n",
    "type_keys = ['d', 'e', 'p', 'pr', 'par', 'c', 'cr', 'car', 'all']\n",
    "type_names = ['D', 'E', 'P', 'PR', 'PAR', 'C', 'CR', 'CAR', 'ALL']\n",
    "\n",
    "summary_data = []\n",
    "for k, name in zip(type_keys, type_names):\n",
    "    v = val_stats[k]\n",
    "    t = test_stats[k]\n",
    "    summary_data.append({\n",
    "        'Type': name,\n",
    "        'Val_Correct': v['correct'],\n",
    "        'Val_Total': v['total'],\n",
    "        'Val_Acc%': round(v['correct']/v['total']*100, 2) if v['total'] > 0 else 0,\n",
    "        'Test_Correct': t['correct'],\n",
    "        'Test_Total': t['total'],\n",
    "        'Test_Acc%': round(t['correct']/t['total']*100, 2) if t['total'] > 0 else 0\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "df.to_csv('evaluation_summary.csv', index=False)\n",
    "print('Saved: evaluation_summary.csv\\n')\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
