# TokenMark (SoM) Issues - Low Accuracy Fix Guide

## üî¥ C√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn g√¢y score th·∫•p

### 1. **frame_feat_dim kh√¥ng kh·ªõp** ‚ö†Ô∏è CRITICAL

**V·∫•n ƒë·ªÅ:**
- Model m·∫∑c ƒë·ªãnh expect `frame_feat_dim=4096` (ResNet + Motion concatenated)
- Nh∆∞ng ViT features ch·ªâ c√≥ `1024` dimensions
- N·∫øu kh√¥ng set ƒë√∫ng, `frame_resize` layer s·∫Ω c√≥ k√≠ch th∆∞·ªõc sai ‚Üí model kh√¥ng h·ªçc ƒë∆∞·ª£c

**Fix:**
```python
# Trong Config class (Cell 5):
frame_feat_dim = 1024  # ‚úÖ ƒê√∫ng cho ViT features
```

**Ki·ªÉm tra:**
- Ch·∫°y Cell 6.5 diagnostic
- Xem "Model frame_feat_dim" c√≥ = 1024 kh√¥ng

---

### 2. **SoM data kh√¥ng ƒë∆∞·ª£c load** ‚ö†Ô∏è HIGH

**V·∫•n ƒë·ªÅ:**
- N·∫øu `som_data` l√† `None` cho h·∫ßu h·∫øt samples, SoM injection kh√¥ng x·∫£y ra
- Model v·∫´n ch·∫°y nh∆∞ng kh√¥ng c√≥ benefit t·ª´ Token Marks

**Fix:**
```python
# Ki·ªÉm tra trong Cell 6.5:
# - SoM available ph·∫£i > 50% samples
# - N·∫øu < 50%, check ƒë∆∞·ªùng d·∫´n SOM_FEATURE_PATH
```

**Debug:**
```python
# Th√™m v√†o Cell 6 sau khi t·∫°o datasets:
for i in range(10):
    sample = train_ds[i]
    som_data = sample[6]
    print(f"Sample {i}: som_data is {'NOT None' if som_data else 'None'}")
```

---

### 3. **use_som flag kh√¥ng nh·∫•t qu√°n** ‚ö†Ô∏è HIGH

**V·∫•n ƒë·ªÅ:**
- `args.use_som` v√† `model.use_som` ph·∫£i gi·ªëng nhau
- N·∫øu kh√°c nhau, training loop c√≥ th·ªÉ kh√¥ng pass `som_data` v√†o model

**Fix:**
```python
# Trong Cell 7, sau khi t·∫°o model:
assert args.use_som == model.use_som, "use_som flags must match!"

# Trong training loop (Cell 4):
if use_som and som_data is not None:  # ‚úÖ ƒê√∫ng
    out = model(ff, of, q, a, som_data=som_data)
else:
    out = model(ff, of, q, a)
```

---

### 4. **Gamma values qu√° nh·ªè** ‚ö†Ô∏è MEDIUM

**V·∫•n ƒë·ªÅ:**
- `gamma_frame` v√† `gamma_obj` qu√° nh·ªè ‚Üí injection effect kh√¥ng ƒë√°ng k·ªÉ
- Default `gamma_init=0.1` c√≥ th·ªÉ qu√° nh·ªè

**Fix:**
```python
# Trong networks/som_injection.py, SoMInjector.__init__:
gamma_init=0.5  # Th·ª≠ tƒÉng t·ª´ 0.1 l√™n 0.5

# Ho·∫∑c sau khi t·∫°o model:
if hasattr(model, 'som_injector'):
    with torch.no_grad():
        model.som_injector.gamma_frame.data.fill_(0.5)
        model.som_injector.gamma_obj.data.fill_(0.5)
```

**Ki·ªÉm tra:**
- Ch·∫°y Cell 6.5, xem "gamma_frame" v√† "gamma_obj" values
- N·∫øu < 0.01, injection g·∫ßn nh∆∞ kh√¥ng c√≥ effect

---

### 5. **idx_frame shape kh√¥ng ƒë√∫ng** ‚ö†Ô∏è MEDIUM

**V·∫•n ƒë·ªÅ:**
- SoMInjector expect `idx_frame: [B, F_orig, frame_topK]`
- Nh∆∞ng sau `frame_sorter`, shape c√≥ th·ªÉ kh√°c

**Fix:**
```python
# Trong model.py forward(), sau frame topK selection:
# idx_frame shape should be [B, F, frame_topK] = [B, 16, 5]

# Verify trong SoMInjector.forward():
if idx_frame is not None:
    assert idx_frame.shape == (B, F_orig, frame_topK), \
        f"idx_frame shape {idx_frame.shape} != expected {(B, F_orig, frame_topK)}"
```

---

### 6. **Entity ID mapping sai** ‚ö†Ô∏è MEDIUM

**V·∫•n ƒë·ªÅ:**
- Entity IDs trong masks c√≥ th·ªÉ non-contiguous (1, 3, 5)
- `entity_to_mark` mapping ph·∫£i handle ƒë√∫ng

**Fix:**
- Code ƒë√£ handle trong `get_active_mark_embeddings()`, nh∆∞ng verify:
```python
# Trong SoMInjector, check entity_to_mark:
entity_ids = sorted(entity_names.keys())  # [1, 3, 5]
entity_to_mark = {eid: idx for idx, eid in enumerate(entity_ids)}  # {1:0, 3:1, 5:2}
```

---

### 7. **Output kh√¥ng h·ªçc ƒë∆∞·ª£c (std qu√° nh·ªè)** ‚ö†Ô∏è CRITICAL

**V·∫•n ƒë·ªÅ:**
- N·∫øu output std < 0.1, model kh√¥ng h·ªçc ƒë∆∞·ª£c g√¨
- C√≥ th·ªÉ do:
  - Learning rate qu√° nh·ªè
  - Gradient b·ªã vanish
  - Features kh√¥ng ƒë∆∞·ª£c normalize ƒë√∫ng

**Fix:**
```python
# Ki·ªÉm tra trong Cell 6.5:
# - Output std ph·∫£i > 0.5
# - N·∫øu < 0.1, th·ª≠:
#   1. TƒÉng learning rate: lr = 5e-5
#   2. Gi·∫£m dropout: dropout = 0.1
#   3. Check gradient flow
```

---

## üîß Quick Fix Checklist

Ch·∫°y Cell 6.5 diagnostic v√† check:

- [ ] `frame_feat_dim == 1024` (cho ViT)
- [ ] `SoM available > 50%` samples
- [ ] `args.use_som == model.use_som`
- [ ] `gamma_frame > 0.01` v√† `gamma_obj > 0.01`
- [ ] `Output std > 0.5`
- [ ] Kh√¥ng c√≥ NaN/Inf trong output
- [ ] SoM data structure ƒë√∫ng (c√≥ `frame_masks` v√† `entity_names`)

---

## üêõ Debug Steps

### Step 1: Verify SoM data loading
```python
# Th√™m v√†o Cell 6:
sample = train_ds[0]
som_data = sample[6]
print(f"SoM data: {som_data}")
if som_data:
    print(f"  Keys: {som_data.keys()}")
    print(f"  Frame masks: {list(som_data['frame_masks'].keys())[:5]}")
    print(f"  Entity names: {som_data['entity_names']}")
```

### Step 2: Test forward pass v·ªõi SoM
```python
# Th√™m v√†o Cell 7 sau khi t·∫°o model:
model.eval()
batch = next(iter(train_loader))
ff, of, q, a, ans_id, _, som_data = batch
ff, of = ff.to(device), of.to(device)

# Test v·ªõi SoM
out_with_som = model(ff, of, q, a, som_data=som_data)
print(f"With SoM: {out_with_som.mean():.2f}, std: {out_with_som.std():.2f}")

# Test kh√¥ng SoM
out_no_som = model(ff, of, q, a, som_data=None)
print(f"No SoM: {out_no_som.mean():.2f}, std: {out_no_som.std():.2f}")

# So s√°nh
diff = (out_with_som - out_no_som).abs().mean()
print(f"Difference: {diff:.4f}")
# N·∫øu diff < 0.01, SoM injection kh√¥ng c√≥ effect!
```

### Step 3: Check gradient flow
```python
# Th√™m v√†o training loop (Cell 10), sau loss.backward():
if ep == 1 and batch_idx == 0:
    total_norm = 0
    for p in model.parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
    total_norm = total_norm ** (1. / 2)
    print(f"Gradient norm: {total_norm:.4f}")
    # N·∫øu < 0.1, gradient qu√° nh·ªè ‚Üí model kh√¥ng h·ªçc
```

---

## üìä Expected Results

### Baseline (kh√¥ng SoM):
- Acc_ALL: ~35-40% (t√πy dataset)
- Description: ~40-50%
- Explanation: ~35-45%

### V·ªõi SoM (n·∫øu ho·∫°t ƒë·ªông ƒë√∫ng):
- Acc_ALL: +2-5% improvement
- Description: +1-3%
- Explanation: +2-4%
- PAR/CAR: +3-6% (v√¨ SoM gi√∫p entity grounding)

### N·∫øu score < 20%:
- ‚ùå Model kh√¥ng h·ªçc ƒë∆∞·ª£c ‚Üí check learning rate, gradient flow
- ‚ùå Features sai ‚Üí check frame_feat_dim
- ‚ùå Data loading sai ‚Üí check DataLoader

---

## üéØ Most Likely Issues (theo th·ª© t·ª±)

1. **frame_feat_dim != 1024** ‚Üí Model resize layer sai ‚Üí kh√¥ng h·ªçc ƒë∆∞·ª£c
2. **SoM data missing** ‚Üí Injection kh√¥ng x·∫£y ra ‚Üí kh√¥ng c√≥ benefit
3. **use_som flags mismatch** ‚Üí SoM kh√¥ng ƒë∆∞·ª£c pass v√†o model
4. **Output std qu√° nh·ªè** ‚Üí Model kh√¥ng h·ªçc ‚Üí check LR, dropout
5. **Gamma qu√° nh·ªè** ‚Üí Injection effect kh√¥ng ƒë√°ng k·ªÉ

---

## ‚úÖ Final Checklist

Tr∆∞·ªõc khi train l·∫°i:

- [ ] Ch·∫°y Cell 6.5 diagnostic
- [ ] Fix t·∫•t c·∫£ warnings
- [ ] Verify SoM data > 50% available
- [ ] Test forward pass v·ªõi/kh√¥ng SoM
- [ ] Check output std > 0.5
- [ ] Verify gradient flow (grad norm > 0.1)
- [ ] Set learning rate ph√π h·ª£p (1e-5 cho DeBERTa)
- [ ] Monitor training loss gi·∫£m d·∫ßn

---

## üìù Notes

- SoM injection ch·ªâ gi√∫p n·∫øu:
  1. SoM data c√≥ s·∫µn cho > 50% samples
  2. Entity grounding th·ª±c s·ª± quan tr·ªçng cho c√¢u h·ªèi
  3. Model baseline ƒë√£ ho·∫°t ƒë·ªông t·ªët (> 30% acc)

- N·∫øu baseline accuracy ƒë√£ th·∫•p (< 20%), fix baseline tr∆∞·ªõc:
  - Check data loading
  - Check feature dimensions
  - Check learning rate
  - Check model architecture
