{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TranSTR + Token Mark (SoM) - Resume Training Support\n",
        "\n",
        "**Features:**\n",
        "- Token Mark (SoM) Injection for entity grounding\n",
        "- DeBERTa text encoder\n",
        "- W&B logging & checkpoint management\n",
        "- **Resume training from W&B checkpoint**\n",
        "- Fix for multiprocessing DataLoader issues\n",
        "\n",
        "---\n",
        "\n",
        "## üî¥ RESUME CONFIGURATION\n",
        "\n",
        "Set `RESUME_FROM_WANDB = True` to resume training from a previous checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 1: Git Clone & Setup\n",
        "# ==============================================================================\n",
        "import os\n",
        "import multiprocessing\n",
        "\n",
        "# Fix multiprocessing for Kaggle/Colab\n",
        "try:\n",
        "    multiprocessing.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    pass  # Already set\n",
        "\n",
        "REPO_URL = \"https://github.com/DanielQH07/tranSTR_Casual.git\" \n",
        "REPO_NAME = \"tranSTR_Casual\"\n",
        "BRANCH = \"daniel_setmark\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"Cloning {REPO_URL}...\")\n",
        "    !git clone {REPO_URL} -b {BRANCH}\n",
        "else:\n",
        "    print(\"Repo already exists.\")\n",
        "\n",
        "# Change Directory\n",
        "if os.path.basename(os.getcwd()) != \"causalvid\":\n",
        "    target_dir = os.path.join(os.getcwd(), REPO_NAME, \"causalvid\")\n",
        "    if os.path.exists(target_dir):\n",
        "        os.chdir(target_dir)\n",
        "    elif os.path.exists(REPO_NAME):\n",
        "        os.chdir(REPO_NAME)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 2: W&B Setup\n",
        "# ==============================================================================\n",
        "print('=== CELL 2: W&B Setup ===')\n",
        "!pip install -q wandb --upgrade\n",
        "import wandb\n",
        "\n",
        "# ============================================\n",
        "# üî¥ W&B CONFIG - UPDATE THESE!\n",
        "# ============================================\n",
        "WANDB_API_KEY = 'YOUR_WANDB_API_KEY_HERE'  # üî¥ REQUIRED\n",
        "WANDB_PROJECT = 'transtr-causalvid'\n",
        "WANDB_ENTITY = None  # Your username or None for default\n",
        "\n",
        "# ============================================\n",
        "# üî¥ RESUME SETTINGS\n",
        "# ============================================\n",
        "RESUME_FROM_WANDB = False  # Set True to resume from checkpoint\n",
        "RESUME_ARTIFACT_NAME = 'best-model-som:latest'  # W&B artifact name\n",
        "\n",
        "# Login\n",
        "wandb.login(key=WANDB_API_KEY, relogin=True)\n",
        "print('‚úÖ W&B logged in!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 3: Imports\n",
        "# ==============================================================================\n",
        "print('=== CELL 3: Imports ===')\n",
        "import os, torch, numpy as np, pandas as pd, json\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from utils.util import set_seed, set_gpu_devices\n",
        "from DataLoader import VideoQADataset\n",
        "from networks.model import VideoQAmodel\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "print('‚úÖ Imports OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 4: Train/Eval Functions with SoM\n",
        "# ==============================================================================\n",
        "print('=== CELL 4: Functions ===')\n",
        "\n",
        "def train_epoch(model, optimizer, loader, xe, device, epoch, use_som=False):\n",
        "    \"\"\"Training with optional SoM injection.\"\"\"\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    pbar = tqdm(loader, desc=f'Epoch {epoch}', leave=False)\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        ff, of, q, a, ans_id, _, som_data = batch\n",
        "        ff, of, tgt = ff.to(device), of.to(device), ans_id.to(device)\n",
        "        \n",
        "        if use_som and som_data is not None:\n",
        "            out = model(ff, of, q, a, som_data=som_data)\n",
        "        else:\n",
        "            out = model(ff, of, q, a)\n",
        "        \n",
        "        loss = xe(out, tgt)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        correct += (out.argmax(-1) == tgt).sum().item()\n",
        "        total += tgt.size(0)\n",
        "        \n",
        "        pbar.set_postfix({'loss': total_loss/(batch_idx+1), 'acc': correct/total*100})\n",
        "        \n",
        "        # Log to W&B every 100 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            wandb.log({\n",
        "                'batch_loss': loss.item(),\n",
        "                'batch_acc': (out.argmax(-1) == tgt).float().mean().item() * 100,\n",
        "                'global_step': epoch * len(loader) + batch_idx\n",
        "            })\n",
        "        \n",
        "        # Clear cache periodically to prevent OOM\n",
        "        if batch_idx % 200 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    return total_loss / len(loader), correct / total * 100\n",
        "\n",
        "def eval_epoch(model, loader, device, use_som=False):\n",
        "    \"\"\"Evaluation with optional SoM injection.\"\"\"\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Eval', leave=False):\n",
        "            ff, of, q, a, ans_id, _, som_data = batch\n",
        "            if use_som and som_data is not None:\n",
        "                out = model(ff.to(device), of.to(device), q, a, som_data=som_data)\n",
        "            else:\n",
        "                out = model(ff.to(device), of.to(device), q, a)\n",
        "            correct += (out.argmax(-1) == ans_id.to(device)).sum().item()\n",
        "            total += ans_id.size(0)\n",
        "    return correct / total * 100\n",
        "\n",
        "print('‚úÖ Functions defined!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 5: Paths & Config\n",
        "# ==============================================================================\n",
        "print('=== CELL 5: Paths & Config ===')\n",
        "\n",
        "# ============================================\n",
        "# KAGGLE INPUT PATHS\n",
        "# ============================================\n",
        "VIT_FEATURE_PATH = '/kaggle/input/vit-features-full-merged'\n",
        "OBJ_FEATURE_PATH = '/kaggle/input/object-detection-causal-full'\n",
        "ANNOTATION_PATH = '/kaggle/input/text-annotation/QA'\n",
        "SPLIT_DIR = '/kaggle/input/casual-vid-data-split/split'\n",
        "SOM_FEATURE_PATH = '/kaggle/input/causal-vqa-object-masks-full/obj_mask_causal_full'\n",
        "\n",
        "# Working directories\n",
        "BASE = '/kaggle/working'\n",
        "MODEL_DIR = os.path.join(BASE, 'models')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Verify paths\n",
        "print('\\n--- Path Verification ---')\n",
        "def verify_path(name, path):\n",
        "    if os.path.exists(path):\n",
        "        items = os.listdir(path)[:3]\n",
        "        print(f'‚úÖ {name}: {items}')\n",
        "        return True\n",
        "    else:\n",
        "        print(f'‚ùå {name}: NOT FOUND - {path}')\n",
        "        return False\n",
        "\n",
        "all_ok = True\n",
        "all_ok &= verify_path('ViT Features', VIT_FEATURE_PATH)\n",
        "all_ok &= verify_path('Object Features', OBJ_FEATURE_PATH)\n",
        "all_ok &= verify_path('Annotations', ANNOTATION_PATH)\n",
        "all_ok &= verify_path('Splits', SPLIT_DIR)\n",
        "som_ok = verify_path('SoM Masks', SOM_FEATURE_PATH)\n",
        "\n",
        "if not all_ok:\n",
        "    print('\\n‚ö†Ô∏è Please update paths above!')\n",
        "\n",
        "# ============================================\n",
        "# CONFIG\n",
        "# ============================================\n",
        "RUN_TRAINING = True\n",
        "MAX_TRAIN_SAMPLES = None  # None = all, or set number for testing\n",
        "MODEL_FILENAME = 'best_model_som.ckpt'\n",
        "CHECKPOINT_FILENAME = 'training_checkpoint.pt'\n",
        "\n",
        "class Config:\n",
        "    # Paths\n",
        "    video_feature_root = VIT_FEATURE_PATH\n",
        "    object_feature_path = OBJ_FEATURE_PATH\n",
        "    sample_list_path = ANNOTATION_PATH\n",
        "    split_dir_txt = SPLIT_DIR\n",
        "    som_feature_path = SOM_FEATURE_PATH if som_ok else None\n",
        "    \n",
        "    # Model architecture\n",
        "    topK_frame = 16\n",
        "    objs = 20\n",
        "    frames = 16\n",
        "    select_frames = 5\n",
        "    topK_obj = 12\n",
        "    frame_feat_dim = 1024\n",
        "    obj_feat_dim = 2053\n",
        "    d_model = 768\n",
        "    word_dim = 768\n",
        "    nheads = 8\n",
        "    num_encoder_layers = 2\n",
        "    num_decoder_layers = 2\n",
        "    normalize_before = True\n",
        "    activation = 'gelu'\n",
        "    dropout = 0.3\n",
        "    encoder_dropout = 0.3\n",
        "    \n",
        "    # Token Mark (SoM) Settings\n",
        "    use_som = som_ok\n",
        "    num_marks = 16\n",
        "    \n",
        "    # Text encoder\n",
        "    text_encoder_type = 'microsoft/deberta-base'\n",
        "    freeze_text_encoder = False\n",
        "    text_encoder_lr = 1e-5\n",
        "    text_pool_mode = 1\n",
        "    \n",
        "    # Training\n",
        "    bs = 8\n",
        "    lr = 1e-5\n",
        "    epoch = 20\n",
        "    gpu = 0\n",
        "    patience = 5\n",
        "    gamma = 0.1\n",
        "    decay = 1e-4\n",
        "    n_query = 5\n",
        "    num_workers = 2  # üî¥ Using 2 workers\n",
        "    \n",
        "    # Other\n",
        "    hard_eval = False\n",
        "    pos_ratio = 1.0\n",
        "    neg_ratio = 1.0\n",
        "    a = 1.0\n",
        "\n",
        "args = Config()\n",
        "set_gpu_devices(args.gpu)\n",
        "set_seed(999)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f'\\nDevice: {device}')\n",
        "print(f'Token Mark (SoM): {\"ENABLED\" if args.use_som else \"DISABLED\"}')\n",
        "print(f'Total Epochs: {args.epoch}')\n",
        "print(f'Num Workers: {args.num_workers}')\n",
        "print('‚úÖ Config loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 6.5: DIAGNOSTIC - Check TokenMark Issues\n",
        "# ==============================================================================\n",
        "print('=== CELL 6.5: Diagnostic Check ===')\n",
        "\n",
        "# 1. Check SoM data availability\n",
        "print('\\n1. Checking SoM data availability...')\n",
        "som_available = 0\n",
        "som_missing = 0\n",
        "sample_som_data = None\n",
        "\n",
        "for i in range(min(100, len(train_ds))):\n",
        "    sample = train_ds[i]\n",
        "    som_data = sample[6]  # Last item is som_data\n",
        "    if som_data is not None:\n",
        "        som_available += 1\n",
        "        if sample_som_data is None:\n",
        "            sample_som_data = som_data\n",
        "    else:\n",
        "        som_missing += 1\n",
        "\n",
        "print(f'   SoM available: {som_available}/{som_available+som_missing} ({som_available/(som_available+som_missing)*100:.1f}%)')\n",
        "print(f'   SoM missing:   {som_missing}/{som_available+som_missing} ({som_missing/(som_available+som_missing)*100:.1f}%)')\n",
        "\n",
        "if sample_som_data:\n",
        "    print(f'\\n   Sample SoM data structure:')\n",
        "    print(f'     Keys: {list(sample_som_data.keys())}')\n",
        "    if 'frame_masks' in sample_som_data:\n",
        "        frame_keys = list(sample_som_data['frame_masks'].keys())\n",
        "        print(f'     Frame masks: {frame_keys[:5]}... (total: {len(frame_keys)})')\n",
        "        if frame_keys:\n",
        "            mask_shape = sample_som_data['frame_masks'][frame_keys[0]].shape\n",
        "            print(f'     Mask shape: {mask_shape}')\n",
        "    if 'entity_names' in sample_som_data:\n",
        "        print(f'     Entity names: {sample_som_data[\"entity_names\"]}')\n",
        "\n",
        "# 2. Check config consistency\n",
        "print('\\n2. Checking config consistency...')\n",
        "print(f'   Model use_som: {args.use_som}')\n",
        "print(f'   Model frame_feat_dim: {args.frame_feat_dim} (should be 1024 for ViT)')\n",
        "print(f'   Model obj_feat_dim: {args.obj_feat_dim}')\n",
        "print(f'   Model d_model: {args.d_model}')\n",
        "print(f'   Model topK_frame (in model): {args.select_frames} (used for selection)')\n",
        "print(f'   DataLoader topK_frame: {args.topK_frame} (used for loading)')\n",
        "print(f'   Model topK_obj: {args.topK_obj}')\n",
        "\n",
        "if args.frame_feat_dim != 1024:\n",
        "    print(f'   ‚ö†Ô∏è WARNING: frame_feat_dim={args.frame_feat_dim}, expected 1024 for ViT!')\n",
        "\n",
        "# 3. Check model forward pass\n",
        "print('\\n3. Testing model forward pass...')\n",
        "model.eval()\n",
        "try:\n",
        "    batch = next(iter(train_loader))\n",
        "    ff, of, q, a, ans_id, _, som_data_batch = batch\n",
        "    ff, of = ff.to(device), of.to(device)\n",
        "    \n",
        "    print(f'   Input shapes:')\n",
        "    print(f'     ff: {ff.shape} (expected [B, 16, 1024])')\n",
        "    print(f'     of: {of.shape} (expected [B, 16, 20, 2053])')\n",
        "    print(f'   SoM data in batch: {[s is not None for s in som_data_batch]}')\n",
        "    print(f'     Available: {sum(1 for s in som_data_batch if s is not None)}/{len(som_data_batch)}')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        if args.use_som:\n",
        "            out = model(ff, of, q, a, som_data=som_data_batch)\n",
        "        else:\n",
        "            out = model(ff, of, q, a)\n",
        "        \n",
        "        print(f'   Output shape: {out.shape} (expected [B, 5])')\n",
        "        print(f'   Output range: [{out.min():.2f}, {out.max():.2f}]')\n",
        "        print(f'   Output mean: {out.mean():.2f}')\n",
        "        print(f'   Output std: {out.std():.2f}')\n",
        "        \n",
        "        # Check if output is reasonable\n",
        "        if out.std() < 0.1:\n",
        "            print(f'   ‚ö†Ô∏è WARNING: Output std is very small ({out.std():.2f}), model may not be learning!')\n",
        "        if torch.isnan(out).any():\n",
        "            print(f'   ‚ùå ERROR: NaN in output!')\n",
        "        if torch.isinf(out).any():\n",
        "            print(f'   ‚ùå ERROR: Inf in output!')\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f'   ‚ùå ERROR in forward pass: {e}')\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 4. Check SoM injection parameters\n",
        "if args.use_som and hasattr(model, 'som_injector'):\n",
        "    print('\\n4. Checking SoM injection parameters...')\n",
        "    som = model.som_injector\n",
        "    print(f'   gamma_frame: {som.gamma_frame.item():.4f}')\n",
        "    print(f'   gamma_obj: {som.gamma_obj.item():.4f}')\n",
        "    print(f'   num_marks: {som.num_marks}')\n",
        "    \n",
        "    if abs(som.gamma_frame.item()) < 0.01:\n",
        "        print(f'   ‚ö†Ô∏è WARNING: gamma_frame is very small, injection may be negligible!')\n",
        "    if abs(som.gamma_obj.item()) < 0.01:\n",
        "        print(f'   ‚ö†Ô∏è WARNING: gamma_obj is very small, injection may be negligible!')\n",
        "\n",
        "# 5. Check training loop logic\n",
        "print('\\n5. Checking training loop logic...')\n",
        "print(f'   Training use_som flag: {args.use_som}')\n",
        "print(f'   Model use_som flag: {model.use_som}')\n",
        "if args.use_som != model.use_som:\n",
        "    print(f'   ‚ö†Ô∏è WARNING: Mismatch between training and model use_som flags!')\n",
        "\n",
        "print('\\n‚úÖ Diagnostic complete!')\n",
        "print('\\nüîç KEY ISSUES TO CHECK:')\n",
        "print('   1. If SoM data is mostly missing, injection won\\'t help')\n",
        "print('   2. If frame_feat_dim != 1024, model resize layer is wrong size')\n",
        "print('   3. If output std is very small, model may not be learning')\n",
        "print('   4. If gamma values are too small, SoM injection has no effect')\n",
        "print('   5. Check if use_som flags are consistent everywhere')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 6: Create Datasets with SoM\n",
        "# ==============================================================================\n",
        "print('=== CELL 6: Datasets ===')\n",
        "\n",
        "def collate_fn_som(batch):\n",
        "    \"\"\"Custom collate that keeps som_data as list of dicts.\"\"\"\n",
        "    ff = torch.stack([item[0] for item in batch])\n",
        "    of = torch.stack([item[1] for item in batch])\n",
        "    qns = [item[2] for item in batch]\n",
        "    ans = [item[3] for item in batch]\n",
        "    ans_id = torch.tensor([item[4] for item in batch])\n",
        "    qns_key = [item[5] for item in batch]\n",
        "    som_data = [item[6] for item in batch]\n",
        "    return ff, of, qns, ans, ans_id, qns_key, som_data\n",
        "\n",
        "print('Creating TRAIN dataset...')\n",
        "train_ds = VideoQADataset(\n",
        "    split='train', n_query=args.n_query, obj_num=args.objs,\n",
        "    sample_list_path=args.sample_list_path,\n",
        "    video_feature_path=args.video_feature_root,\n",
        "    object_feature_path=args.object_feature_path,\n",
        "    split_dir=args.split_dir_txt, topK_frame=args.topK_frame,\n",
        "    max_samples=MAX_TRAIN_SAMPLES, verbose=True,\n",
        "    som_feature_path=args.som_feature_path\n",
        ")\n",
        "\n",
        "print('\\nCreating VAL dataset...')\n",
        "val_ds = VideoQADataset(\n",
        "    split='val', n_query=args.n_query, obj_num=args.objs,\n",
        "    sample_list_path=args.sample_list_path,\n",
        "    video_feature_path=args.video_feature_root,\n",
        "    object_feature_path=args.object_feature_path,\n",
        "    split_dir=args.split_dir_txt, topK_frame=args.topK_frame,\n",
        "    max_samples=None, verbose=True,\n",
        "    som_feature_path=args.som_feature_path\n",
        ")\n",
        "\n",
        "print('\\nCreating TEST dataset...')\n",
        "test_ds = VideoQADataset(\n",
        "    split='test', n_query=args.n_query, obj_num=args.objs,\n",
        "    sample_list_path=args.sample_list_path,\n",
        "    video_feature_path=args.video_feature_root,\n",
        "    object_feature_path=args.object_feature_path,\n",
        "    split_dir=args.split_dir_txt, topK_frame=args.topK_frame,\n",
        "    max_samples=None, verbose=True,\n",
        "    som_feature_path=args.som_feature_path\n",
        ")\n",
        "\n",
        "# Create DataLoaders with persistent_workers to avoid recreation issues\n",
        "train_loader = DataLoader(\n",
        "    train_ds, args.bs, shuffle=True, \n",
        "    num_workers=args.num_workers, \n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn_som,\n",
        "    persistent_workers=True if args.num_workers > 0 else False,\n",
        "    prefetch_factor=2 if args.num_workers > 0 else None\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, args.bs, shuffle=False, \n",
        "    num_workers=args.num_workers, \n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn_som,\n",
        "    persistent_workers=True if args.num_workers > 0 else False,\n",
        "    prefetch_factor=2 if args.num_workers > 0 else None\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds, args.bs, shuffle=False, \n",
        "    num_workers=args.num_workers, \n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn_som,\n",
        "    persistent_workers=True if args.num_workers > 0 else False,\n",
        "    prefetch_factor=2 if args.num_workers > 0 else None\n",
        ")\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('DATASET SUMMARY')\n",
        "print('='*60)\n",
        "print(f'Train: {len(train_ds)} samples -> {len(train_loader)} batches')\n",
        "print(f'Val:   {len(val_ds)} samples -> {len(val_loader)} batches')\n",
        "print(f'Test:  {len(test_ds)} samples -> {len(test_loader)} batches')\n",
        "print(f'SoM:   {\"ENABLED\" if args.som_feature_path else \"DISABLED\"}')\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 7: Create Model & Optimizer\n",
        "# ==============================================================================\n",
        "print('=== CELL 7: Model ===')\n",
        "\n",
        "cfg = {k: v for k, v in Config.__dict__.items() if not k.startswith('_')}\n",
        "cfg['device'] = device\n",
        "cfg['topK_frame'] = args.select_frames\n",
        "cfg['use_som'] = args.use_som\n",
        "cfg['num_marks'] = args.num_marks\n",
        "\n",
        "model = VideoQAmodel(**cfg)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=args.gamma, patience=args.patience)\n",
        "xe = nn.CrossEntropyLoss()\n",
        "\n",
        "save_path = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
        "checkpoint_path = os.path.join(MODEL_DIR, CHECKPOINT_FILENAME)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Total params:     {total_params/1e6:.1f}M')\n",
        "print(f'Trainable params: {trainable_params/1e6:.1f}M')\n",
        "print(f'SoM Enabled:      {args.use_som}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 8: Resume from Checkpoint (if enabled)\n",
        "# ==============================================================================\n",
        "print('=== CELL 8: Resume Logic ===')\n",
        "\n",
        "start_epoch = 1\n",
        "best_acc = 0\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "# ============================================\n",
        "# RESUME FROM W&B CHECKPOINT\n",
        "# ============================================\n",
        "if RESUME_FROM_WANDB:\n",
        "    print(f'\\nüîÑ Resuming from W&B artifact: {RESUME_ARTIFACT_NAME}')\n",
        "    \n",
        "    try:\n",
        "        # Temp run to download artifact\n",
        "        temp_run = wandb.init(\n",
        "            project=WANDB_PROJECT,\n",
        "            entity=WANDB_ENTITY,\n",
        "            job_type='download',\n",
        "            reinit=True\n",
        "        )\n",
        "        \n",
        "        artifact = temp_run.use_artifact(RESUME_ARTIFACT_NAME, type='model')\n",
        "        artifact_dir = artifact.download()\n",
        "        \n",
        "        # Find checkpoint file\n",
        "        ckpt_files = [f for f in os.listdir(artifact_dir) if f.endswith('.ckpt') or f.endswith('.pt')]\n",
        "        if ckpt_files:\n",
        "            ckpt_path = os.path.join(artifact_dir, ckpt_files[0])\n",
        "            \n",
        "            # Load model weights\n",
        "            state_dict = torch.load(ckpt_path, map_location=device)\n",
        "            model.load_state_dict(state_dict)\n",
        "            print(f'‚úÖ Model weights loaded from: {ckpt_path}')\n",
        "            \n",
        "            # Get epoch from artifact metadata\n",
        "            if artifact.metadata:\n",
        "                start_epoch = artifact.metadata.get('epoch', 0) + 1\n",
        "                best_acc = artifact.metadata.get('val_acc', 0)\n",
        "                print(f'‚úÖ Resume from epoch {start_epoch}, best_acc={best_acc:.2f}%')\n",
        "        \n",
        "        temp_run.finish()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f'‚ö†Ô∏è Could not resume from W&B: {e}')\n",
        "        print('Starting fresh training...')\n",
        "        start_epoch = 1\n",
        "        best_acc = 0\n",
        "\n",
        "# ============================================\n",
        "# CHECK LOCAL CHECKPOINT (fallback)\n",
        "# ============================================\n",
        "if not RESUME_FROM_WANDB and os.path.exists(checkpoint_path):\n",
        "    print(f'\\nüîÑ Found local checkpoint: {checkpoint_path}')\n",
        "    user_input = input('Load local checkpoint? (y/n): ').strip().lower()\n",
        "    \n",
        "    if user_input == 'y':\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            start_epoch = checkpoint['epoch'] + 1\n",
        "            best_acc = checkpoint['best_acc']\n",
        "            history = checkpoint.get('history', history)\n",
        "            print(f'‚úÖ Resumed from local checkpoint at epoch {start_epoch}')\n",
        "        except Exception as e:\n",
        "            print(f'‚ö†Ô∏è Could not load local checkpoint: {e}')\n",
        "\n",
        "print(f'\\nüìå Training will start from epoch {start_epoch}')\n",
        "print(f'üìå Best accuracy so far: {best_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 9: Initialize W&B Training Run\n",
        "# ==============================================================================\n",
        "print('=== CELL 9: Init W&B Run ===')\n",
        "\n",
        "wandb_config = {\n",
        "    'model': 'TranSTR-SoM',\n",
        "    'text_encoder': args.text_encoder_type,\n",
        "    'batch_size': args.bs,\n",
        "    'learning_rate': args.lr,\n",
        "    'total_epochs': args.epoch,\n",
        "    'start_epoch': start_epoch,\n",
        "    'max_train_samples': MAX_TRAIN_SAMPLES,\n",
        "    'd_model': args.d_model,\n",
        "    'nheads': args.nheads,\n",
        "    'num_encoder_layers': args.num_encoder_layers,\n",
        "    'num_decoder_layers': args.num_decoder_layers,\n",
        "    'dropout': args.dropout,\n",
        "    'topK_frame': args.select_frames,\n",
        "    'topK_obj': args.topK_obj,\n",
        "    'train_samples': len(train_ds),\n",
        "    'val_samples': len(val_ds),\n",
        "    'test_samples': len(test_ds),\n",
        "    'use_som': args.use_som,\n",
        "    'num_marks': args.num_marks,\n",
        "    'num_workers': args.num_workers,\n",
        "    'resumed': start_epoch > 1,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=WANDB_PROJECT,\n",
        "    entity=WANDB_ENTITY,\n",
        "    config=wandb_config,\n",
        "    name=f'transtr-som-ep{start_epoch}-{args.epoch}',\n",
        "    resume='allow',\n",
        "    reinit=True\n",
        ")\n",
        "\n",
        "wandb.watch(model, log='gradients', log_freq=200)\n",
        "print(f'‚úÖ W&B Run: {run.url}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 10: Training Loop with Resume Support\n",
        "# ==============================================================================\n",
        "print('=== CELL 10: Training ===')\n",
        "\n",
        "if RUN_TRAINING:\n",
        "    print('\\n' + '='*60)\n",
        "    print('üöÄ STARTING TRAINING')\n",
        "    print('='*60)\n",
        "    print(f'Epochs: {start_epoch} to {args.epoch}')\n",
        "    print(f'Best Val Acc: {best_acc:.2f}%')\n",
        "    print('='*60)\n",
        "    \n",
        "    for ep in range(start_epoch, args.epoch + 1):\n",
        "        print(f'\\nEpoch {ep}/{args.epoch}')\n",
        "        \n",
        "        # Train\n",
        "        loss, train_acc = train_epoch(\n",
        "            model, optimizer, train_loader, xe, device, ep,\n",
        "            use_som=args.use_som\n",
        "        )\n",
        "        \n",
        "        # Validate\n",
        "        val_acc = eval_epoch(model, val_loader, device, use_som=args.use_som)\n",
        "        scheduler.step(val_acc)\n",
        "        \n",
        "        # Update history\n",
        "        history['train_loss'].append(loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        \n",
        "        # Log to W&B\n",
        "        wandb.log({\n",
        "            'epoch': ep,\n",
        "            'train_loss': loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
        "            'best_val_acc': max(best_acc, val_acc)\n",
        "        })\n",
        "        \n",
        "        print(f'Loss: {loss:.4f} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}%')\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f'‚úÖ New best! Saved to {save_path}')\n",
        "            \n",
        "            # Upload to W&B\n",
        "            artifact = wandb.Artifact(\n",
        "                name='best-model-som',\n",
        "                type='model',\n",
        "                description=f'Best TranSTR-SoM at epoch {ep}',\n",
        "                metadata={\n",
        "                    'epoch': ep,\n",
        "                    'val_acc': val_acc,\n",
        "                    'train_acc': train_acc,\n",
        "                    'train_loss': loss,\n",
        "                    'use_som': args.use_som\n",
        "                }\n",
        "            )\n",
        "            artifact.add_file(save_path)\n",
        "            wandb.log_artifact(artifact)\n",
        "            print('üì§ Uploaded to W&B!')\n",
        "        \n",
        "        # Save full checkpoint EVERY epoch for resume\n",
        "        torch.save({\n",
        "            'epoch': ep,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'history': history,\n",
        "        }, checkpoint_path)\n",
        "        print(f'üíæ Checkpoint saved')\n",
        "        \n",
        "        # Upload checkpoint artifact every 5 epochs\n",
        "        if ep % 5 == 0 or ep == args.epoch:\n",
        "            ckpt_artifact = wandb.Artifact(\n",
        "                name=f'checkpoint-ep{ep}',\n",
        "                type='checkpoint',\n",
        "                description=f'Training checkpoint at epoch {ep}',\n",
        "                metadata={'epoch': ep, 'val_acc': val_acc, 'best_acc': best_acc}\n",
        "            )\n",
        "            ckpt_artifact.add_file(checkpoint_path)\n",
        "            wandb.log_artifact(ckpt_artifact)\n",
        "            print(f'üì§ Checkpoint artifact uploaded!')\n",
        "        \n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    print(f'\\nüèÜ Training Complete! Best Val Accuracy: {best_acc:.1f}%')\n",
        "    \n",
        "    # Final summary\n",
        "    wandb.run.summary['best_val_acc'] = best_acc\n",
        "    wandb.run.summary['final_epoch'] = ep\n",
        "    wandb.run.summary['total_epochs_trained'] = ep - start_epoch + 1\n",
        "    wandb.run.summary['use_som'] = args.use_som\n",
        "\n",
        "else:\n",
        "    print('Skipping training (RUN_TRAINING=False)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 11: Detailed Evaluation\n",
        "# ==============================================================================\n",
        "print('=== CELL 11: Detailed Evaluation ===')\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_detailed(model, loader, device, use_som=False, split_name='val', log_to_wandb=True):\n",
        "    \"\"\"Detailed evaluation with per-type accuracy.\"\"\"\n",
        "    model.eval()\n",
        "    type_results = {}\n",
        "    \n",
        "    print(f\"\\nüìä Running {split_name.upper()} Evaluation...\")\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=f'Eval {split_name}'):\n",
        "            ff, of, qns, ans_word, ans_id, qns_keys, som_data = batch\n",
        "            ff, of = ff.to(device), of.to(device)\n",
        "            \n",
        "            if use_som and som_data is not None:\n",
        "                out = model(ff, of, qns, ans_word, som_data=som_data)\n",
        "            else:\n",
        "                out = model(ff, of, qns, ans_word)\n",
        "            \n",
        "            preds = out.argmax(dim=-1).cpu().numpy()\n",
        "            targets = ans_id.numpy()\n",
        "            \n",
        "            del out, ff, of\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            for key, pred, target in zip(qns_keys, preds, targets):\n",
        "                # Parse question type\n",
        "                if key.endswith('_reason'):\n",
        "                    if '_predictive_reason' in key:\n",
        "                        qtype = 'predictive_reason'\n",
        "                    elif '_counterfactual_reason' in key:\n",
        "                        qtype = 'counterfactual_reason'\n",
        "                    else:\n",
        "                        parts = key.rsplit('_', 2)\n",
        "                        qtype = '_'.join(parts[1:]) if len(parts) > 1 else 'unknown'\n",
        "                else:\n",
        "                    parts = key.rsplit('_', 1)\n",
        "                    qtype = parts[1] if len(parts) == 2 else 'unknown'\n",
        "                \n",
        "                video_id = key.split('_')[0] if '_' in key else key\n",
        "                \n",
        "                if qtype not in type_results:\n",
        "                    type_results[qtype] = []\n",
        "                type_results[qtype].append({\n",
        "                    'video_id': video_id,\n",
        "                    'pred': int(pred),\n",
        "                    'target': int(target),\n",
        "                    'correct': int(pred) == int(target)\n",
        "                })\n",
        "    \n",
        "    # Calculate metrics\n",
        "    metrics = {}\n",
        "    metrics_map = {\n",
        "        'Description': 'descriptive',\n",
        "        'Explanation': 'explanatory',\n",
        "        'Predictive-Answer': 'predictive',\n",
        "        'Predictive-Reason': 'predictive_reason',\n",
        "        'Counterfactual-Answer': 'counterfactual',\n",
        "        'Counterfactual-Reason': 'counterfactual_reason'\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"EVALUATION RESULTS - {split_name.upper()}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for name, qtype in metrics_map.items():\n",
        "        if qtype in type_results:\n",
        "            results = type_results[qtype]\n",
        "            correct = sum(1 for r in results if r['correct'])\n",
        "            total = len(results)\n",
        "            acc = correct / total * 100 if total > 0 else 0\n",
        "        else:\n",
        "            correct, total, acc = 0, 0, 0\n",
        "        metrics[name] = acc\n",
        "        print(f\"{name:<25} ==>   {acc:.2f}%  ({correct}/{total})\")\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Hard metrics\n",
        "    def calc_hard_metric(type_ans, type_reason, name):\n",
        "        if type_ans not in type_results or type_reason not in type_results:\n",
        "            metrics[name] = 0\n",
        "            print(f\"{name:<25} ==>   0.00%  (0/0 paired)\")\n",
        "            return\n",
        "        \n",
        "        ans_by_vid = {r['video_id']: r['correct'] for r in type_results[type_ans]}\n",
        "        reason_by_vid = {r['video_id']: r['correct'] for r in type_results[type_reason]}\n",
        "        common_vids = set(ans_by_vid.keys()) & set(reason_by_vid.keys())\n",
        "        \n",
        "        both_correct = sum(1 for vid in common_vids if ans_by_vid[vid] and reason_by_vid[vid])\n",
        "        total = len(common_vids)\n",
        "        acc = both_correct / total * 100 if total > 0 else 0\n",
        "        metrics[name] = acc\n",
        "        print(f\"{name:<25} ==>   {acc:.2f}%  ({both_correct}/{total} paired)\")\n",
        "    \n",
        "    calc_hard_metric('predictive', 'predictive_reason', 'PAR')\n",
        "    calc_hard_metric('counterfactual', 'counterfactual_reason', 'CAR')\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Acc (ALL)\n",
        "    d_acc = metrics.get('Description', 0)\n",
        "    e_acc = metrics.get('Explanation', 0)\n",
        "    par_acc = metrics.get('PAR', 0)\n",
        "    car_acc = metrics.get('CAR', 0)\n",
        "    acc_all = (d_acc + e_acc + par_acc + car_acc) / 4\n",
        "    metrics['Acc_ALL'] = acc_all\n",
        "    print(f\"{'Acc (ALL)':<25} ==>   {acc_all:.2f}%  ((D+E+PAR+CAR)/4)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Log to W&B\n",
        "    if log_to_wandb:\n",
        "        wandb.log({\n",
        "            f'{split_name}/Description': metrics['Description'],\n",
        "            f'{split_name}/Explanation': metrics['Explanation'],\n",
        "            f'{split_name}/PAR': metrics['PAR'],\n",
        "            f'{split_name}/CAR': metrics['CAR'],\n",
        "            f'{split_name}/Acc_ALL': acc_all\n",
        "        })\n",
        "        print('üì§ Metrics logged to W&B!')\n",
        "    \n",
        "    return metrics, type_results\n",
        "\n",
        "# Load best model\n",
        "if os.path.exists(save_path):\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "    print(f'Loaded best model from {save_path}')\n",
        "\n",
        "# Evaluate on VAL\n",
        "print(\"\\nüìå VALIDATION SET\")\n",
        "val_metrics, val_raw = evaluate_detailed(\n",
        "    model, val_loader, device, \n",
        "    use_som=args.use_som, split_name='val'\n",
        ")\n",
        "\n",
        "# Evaluate on TEST\n",
        "print(\"\\nüìå TEST SET\")\n",
        "test_metrics, test_raw = evaluate_detailed(\n",
        "    model, test_loader, device, \n",
        "    use_som=args.use_som, split_name='test'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 12: Save Results & Finish\n",
        "# ==============================================================================\n",
        "print('=== CELL 12: Save & Finish ===')\n",
        "\n",
        "# Compare VAL vs TEST\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä VALIDATION vs TEST COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Metric':<25} {'Val':>10} {'Test':>10} {'Diff':>10}\")\n",
        "print(\"-\"*70)\n",
        "for key in ['Description', 'Explanation', 'PAR', 'CAR', 'Acc_ALL']:\n",
        "    val_v = val_metrics.get(key, 0)\n",
        "    test_v = test_metrics.get(key, 0)\n",
        "    diff = test_v - val_v\n",
        "    symbol = '‚Üë' if diff > 0 else ('‚Üì' if diff < 0 else '=')\n",
        "    print(f\"{key:<25} {val_v:>9.2f}% {test_v:>9.2f}% {diff:>+9.2f}% {symbol}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'best_val_acc': best_acc,\n",
        "    'validation': val_metrics,\n",
        "    'test': test_metrics,\n",
        "    'use_som': args.use_som,\n",
        "    'num_marks': args.num_marks,\n",
        "    'epochs_trained': len(history['train_loss']),\n",
        "    'history': history\n",
        "}\n",
        "\n",
        "with open('final_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print('\\nüìÅ Saved: final_results.json')\n",
        "\n",
        "# Log final artifact\n",
        "final_artifact = wandb.Artifact(\n",
        "    name='final-results',\n",
        "    type='results',\n",
        "    description='Final evaluation results'\n",
        ")\n",
        "final_artifact.add_file('final_results.json')\n",
        "if os.path.exists(save_path):\n",
        "    final_artifact.add_file(save_path)\n",
        "wandb.log_artifact(final_artifact)\n",
        "\n",
        "# Update summary\n",
        "wandb.run.summary['test_Acc_ALL'] = test_metrics['Acc_ALL']\n",
        "wandb.run.summary['test_PAR'] = test_metrics['PAR']\n",
        "wandb.run.summary['test_CAR'] = test_metrics['CAR']\n",
        "\n",
        "# Finish W&B\n",
        "wandb.finish()\n",
        "print('\\n‚úÖ Done! Check W&B for full results.')\n",
        "print(f'View at: https://wandb.ai/{WANDB_ENTITY or \"your-username\"}/{WANDB_PROJECT}')"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
